表单数据又称二维表，是传统机器学习所处理的数据类型，其中每列是任意类型（包括字符型和数值型）的字段，每行是由字段值构成的记录。表单数据的模型服务包括模型训练、字段预处理、自动调参、自动算法选择、模型预测、批量预测、模型评估、模型查询和删除等。
## **模型训练**
模型训练是机器学习的基础步骤，通过训练数据集来训练模型，使其能够学习到数据的特征和规律，从而对新的数据进行预测。在AiSQL中，模型训练支持分类、回归和聚类三种主流机器学习任务，并支持AutoML（自动算法选择和自动调参）机制，以实现最佳预测效果。表单数据的模型训练可以通过下述SQL语句进行：
```
select * from aisql.train(project_name text, task text, relation_name text, x_column_names text[], y_column_names text[] default NULL, cat_columns integer[] default NULL, algorithm text default NULL, hyperparams text default '{}', search text default NULL, search_params text default '{}', search_args text default '{}', preprocess text default '{}');
```

其中，参数说明如下：
project_name：项目名称，用于保存训练好的模型。
task：任务类型，支持分类、回归和聚类三种任务。
relation_name：数据表名称，用于指定训练数据集。
x_column_names：特征列名称数组，用于指定训练数据集中的特征列。
y_column_names：标签列名称数组，用于指定训练数据集中的标签列，默认为NULL，其中NULL仅适用于聚类任务，多个标签列对应多个预测目标。
cat_columns：类别列索引，用于指定训练数据集中的类别列，默认为NULL，其中类别列是字符型字段，该参数非NULL时适用于能直接处理类别列的catboost算法。
algorithm：算法名称，用于指定训练算法，默认为NULL，其中NULL表示针对指定任务的所有算法进行模型训练。
hyperparams：JSON格式的算法超参数定义，用于指定训练算法的超参数，默认为空的JSON对象{}，其中{}表示使用默认的超参数。
search：超参数搜索策略，用于指定训练算法的超参数搜索策略，默认为NULL，其中NULL表示不进行超参数调优。
search_params：JSON格式的超参数搜索范围定义，用于指定训练算法的超参数调优范围，默认为空的JSON对象{}，其中{}意味着实际上不进行超参数调优。
search_args：JSON格式的超参数搜索算法的参数，用于控制超参数搜索行为，比如迭代次数，默认为空的JSON对象{}，其中{}表示使用默认的超参数搜索算法参数。
preprocess：JSON格式的数据预处理定义，用于指定训练数据集各个字段（包括特征列和标签列）的数据预处理方法，默认为空的JSON对象{}，其中{}表示不进行数据预处理。

该SQL语句的返回值是一个数据视图，由(项目ID，模型名，算法:超参数)三个字段的记录构成。

## **字段预处理**
字段预处理是机器学习模型训练前的必要步骤，用于将原始数据转换为适合模型训练的格式。在AiSQL中，字段预处理支持数值型和字符型字段的预处理，包括归一化、标准化、独热编码和标签编码等。字段预处理可以通过模型训练SQL语句的preprocess参数进行指定。preprocess参数值是一个JSON映射表，其中每个键值对表示一个字段的数据预处理方法，规格如下：
```
"字段名": {"预处理方法1": {"参数名11": 参数值11, "参数名12": 参数值12, ...}, "预处理方法2": {"参数名21": 参数值21, "参数名22": 参数值22, ...}, ...}
```

其中，单个字段可以指定多个预处理方法，并按照顺序依次执行；字段名可以是特征列名称，也可以是标签列名称，也可以是全体特征列（不含标签列）的匹配字符串ALL_X，以下述简写形式为全体特征列定义相同的预处理过程：
```
"_ALL_X_": {"预处理方法1": {"参数名11": 参数值11, "参数名12": 参数值12, ...}, "预处理方法2": {"参数名21": 参数值21, "参数名22": 参数值22, ...}, ...}
```

AI特性插件支持多种字段预处理方法，包括以下几种，其中编号后的小写字符串是对应预处理方法在preprocess参数值中采用的名称：
1.target：目标编码器 (TargetEncoder)
目标编码器是一种用于对字符型特征进行编码的算法。它通过计算指定字符型特征对应的平均目标值（即目标变量）来将字符型特征转换为数值型特征。这样可以使得字符型特征具有更明显的物理含义，便于模型进行学习和分析。
常用参数:
（1）categories: 类别型特征的类别。可以是"auto"（自动确定），也可以是一个列表，列表中的每个元素代表一个特征的类别。如果设置为"auto"，则从训练数据中自动确定类别。
（2）target_type: 目标变量的类型。可以是"auto"（自动确定）、"continuous"（连续型）或"binary"（二分类）。如果设置为"auto"，则使用type_of_target函数自动推断目标变量的类型。目标编码器仅支持"continuous"（连续型）或"binary"（二分类）两种目标变量类型。

（3）smooth: 平滑参数。用于平衡类别平均值和全局目标平均值之间的权重。如果设置为"auto"，则使用经验贝叶斯估计。

2.one_hot：独热编码器 (OneHotEncoder)
独热编码器是一种用于对字符型特征进行编码的算法。它将指定字符型特征转换为一个新的二进制特征，使得该字符型特征值可以表示为一个向量。这样可以使得模型能够更好地学习字符型特征之间的差异。
常用参数: 
（1）categories: 类别型特征的类别。可以是"auto"（自动确定），也可以是一个列表，列表中的每个元素代表一个特征的类别。如果设置为"auto"，则从训练数据中自动确定类别。
（2）drop: 指定在特征中删除一个类别的方法。可以是'first'，表示删除每个特征中的第一个类别；也可以是'if_binary'，表示如果特征中有两个类别，则删除第一个类别；还可以是一个数组，数组中的每个元素表示应该删除的特征中的类别。
（3）sparse_output: 布尔值，如果设置为True，则返回稀疏矩阵，否则返回数组。
（4）handle_unknown: 指定在转换过程中处理未知类别的方法。可以是'error'，表示如果遇到未知类别则抛出错误；可以是'ignore'，表示在转换过程中忽略未知类别；还可以是'infrequent_if_exist'，表示如果存在未知类别，则将其映射到稀有类别（如果存在）。
（5）min_frequency: 指定类别最小出现次数，用于确定稀有类别。
（6）max_categories: 指定最大类别数，用于确定稀有类别。

3.ordinal：序号编码器 (OrdinalEncoder)
序号编码器是一种用于对字符型特征进行编码的算法。它将指定字符型特征转换为一个连续的整数值，使得每个字符型特征值可以表示为有序自然数列中的一个元素。这样可以使得模型能够更好地学习字符型特征之间的顺序关系。
常用参数:
（1）categories：类别型特征的类别。可以是"auto"（自动确定），也可以是一个列表，列表中的每个元素代表一个特征的类别。如果设置为"auto"，则从训练数据中自动确定类别。
（2）handle_unknown：{'error', 'use_encoded_value'}, 默认值为'error'。当设置为'error'时，如果在transform过程中出现未知类别，将引发错误。当设置为'use_encoded_value'时，将使用unknown_value参数给未知类别设置编码值。在inverse_transform中，未知类别将被表示为None。
（3）unknown_value：int，默认值为None（设置默认值时不定义unknown_value参数）。当handle_unknown设置为'use_encoded_value'时，此参数是必需的，并且将设置未知类别的编码值。

4.standard：标准缩放器 (StandardScaler)
标准缩放器是一种用于对数值型特征进行标准化处理的算法。它通过计算指定数值型特征的均值和标准差，然后将每个特征值减去均值并除以标准差，使得每个特征具有相同的分布。这样可以使得模型能够更好地学习数值型特征之间的差异。
常用参数:
（1）with_mean: 布尔值，默认为True。如果为True，则计算均值并从指定特征中减去均值。
（2）with_std: 布尔值，默认为True。如果为True，则计算标准差并除以指定特征的标准差。

5.min_max：最小最大缩放器 (MinMaxScaler)
最小最大缩放器是一种用于对数值型特征进行归一化处理的算法。它通过计算指定数值型特征的最小值和最大值，然后将每个特征值减去最小值并除以最大值和最小值之差，使得每个特征的值被缩放到默认为[0,1]的指定区间，这样可以使得模型能够更好地学习数值型特征之间的差异。
常用参数:
（1）feature_range: (min, max)，默认为(0, 1)。指定缩放后的特征值范围。在JSON文本中使用双中括号[[min, max]]表示特征值范围。

6.max_abs：最大绝对缩放器 (MaxAbsScaler)
最大绝对缩放器是一种用于对数值型特征进行归一化处理的算法。它通过计算指定数值型特征的最大绝对值，然后将每个特征值除以最大绝对值，使得每个特征的值被缩放到[-1,1]区间。这样可以使得模型能够更好地学习数值型特征之间的差异。
常用参数: 无

7.robust：鲁棒缩放器 (RobustScaler)
鲁棒缩放器是一种用于对数值型特征进行标准化处理的算法。它通过计算指定数值型特征的均值和四分位数，然后将每个特征值减去均值并除以四分位数，这样可以使得模型能够更好地学习数值型特征之间的差异。
常用参数: 
（1）with_centering: 布尔值，默认为True。如果为True，则计算均值并从指定特征中减去均值。
（2）with_scaling: 布尔值，默认为True。如果为True，则计算四分位数并除以指定特征的四分位数。

8.impute：缺失值填充器 (Imputer)
缺失值填充器是一种用于对数值型特征进行缺失值填充的算法。它或者通过计算指定数值型特征的均值、中位数或众数，然后将缺失值填充为计算得到的值，或者将缺失值填充为指定常数，这样可以使得模型能够更好地学习数值型特征之间的差异。
常用参数:
（1）missing_values: int, float, str，默认为numpy.nan（设置默认值时不定义missing_values参数）。这个参数用来指定哪些值被视为缺失值。所有出现的missing_values都会被填充。
（2）strategy: str，默认为"mean"。这个参数指定缺失值填充的策略。如果为"mean"，则使用每列的平均值来填充缺失值。只能用于数值数据。如果为"median"，则使用每列的中位数来填充缺失值。只能用于数值数据。如果为"most_frequent"，则使用每列出现次数最多的值来填充缺失值。可用于字符串或数值数据。如果有多个这样的值，只返回最小的。如果为"constant"，则使用fill_value来填充所有缺失值。可用于字符串或数值数据。
（3）fill_value: str或数值，默认为None（设置默认值时不定义fill_value参数）。当strategy="constant"时，fill_value用来替换所有缺失值。对于字符串或对象数据类型，fill_value必须是一个字符串。如果为None，当处理数值数据时，fill_value将为0；当处理字符串或对象数据类型时，fill_value将为"missing_value"。

9.encode: 标签编码器 (LabelEncoder)

标签编码器是一种用于对标签列进行编码的算法。它将标签列转换为数值型特征，使得模型能够更好地学习特征列与标签列之间的关联性。该编码器相当于针对特征列的序号编码器，但只对标签列进行编码。
常用参数: 无

下面是一些关于preprocess参数的示例：
```
-- 对特征列parents进行序号编码，转成数值列后再进行区间为[-1,1]的最小最大缩放；同时，对特征列hus_nus进行序号编码，转成数值列后再将缺失值填充为0  
preprocess=>'{"parents":{"ordinal":{},"min_max":{"feature_range":[[-1,1]]}}, "has_nurs":{"ordinal":{},"impute":{"strategy":"constant","fill_value":0}}}'  
  
-- 对特征列form进行序号编码，转成数值列后再进行归一化处理；同时，对特征列children进行序号编码，转成数值列后再将缺失值填充为children的均值  
preprocess=>'{"form":{"ordinal":{},"standard":{}}, "children":{"ordinal":{},"impute":{"strategy":"mean"}}}'  
  
-- 对特征列finance进行独热编码处理  
preprocess=>'{finance":{"one_hot":{}}}'  
  
-- 对特征列health和标签列class均进行序号编码处理  
preprocess=>'{"health":{"ordinal":{}}, "class":{"encode":{}}}'
 
```

作为一个例子，下面几个SQL语句展示了如何导入训练集并基于该训练集预处理所有特征列和标签列，同时根据预处理后的数据集训练一个随机森林模型：
```
-- 导入训练集  
create table aisql.nursery(parents varchar, has_nurs varchar, form varchar, children varchar, housing varchar, finance varchar, social varchar, health varchar, class varchar);  
copy aisql.nursery from 'path/to/nursery.data' (format csv, header false, delimiter ',', encoding 'utf-8');  
  
-- 训练随机森林模型  
select aisql.train(project_name=>'nursery.random_forest.classification', task=>'classification', algorithm=>'random_forest', relation_name=>'aisql.nursery', x_column_names=>'{parents,has_nurs,form,children,housing,finance,social,health}'::text[], y_column_names=>'{class}'::text[], preprocess=>'{"parents":{"ordinal":{},"min_max":{"feature_range":[[-1,1]]}},"has_nurs":{"ordinal":{},"impute":{"strategy":"constant"}},"form":{"ordinal":{},"standard":{}},"children":{"ordinal":{},"impute":{"strategy":"mean"}},"housing":{"ordinal":{}},"finance":{"one_hot":{}},"social":{"ordinal":{}},"health":{"ordinal":{}},"class":{"encode":{}}}');
```

上述例子中的训练集源自最初为对托儿所申请进行排名而开发的分层决策模型，可以从[这里](http://archive.ics.uci.edu/dataset/76/nursery)下载。
模型训练完成后，可以通过以下SQL语句将项目中的对应预处理模型应用到指定表单中的指定字段，产生(行号，预处理后字段值)构成的两列数据视图：
```
select * from aisql.preprocess(column_name text, relation_name text, project_name text default NULL);
```

其中，参数说明如下：
column_name: 预处理模型对应的字段名，即preprocess参数中指定的字段名。
relation_name: 待预处理的数据表单名。
project_name: 预处理模型对应的项目名。当项目名为空时，直接产生由(行号，原始字段值)构成的两列数据视图。

通过行号作为合并主键，将各个字段应用预处理模型后得到的数据视图进行合并，即可得到预处理后的数据表。
比如，将上面例子中nursery.random_forest.classification项目所产生的对应预处理模型应用到aisql.nursery表单中的parents、finance和class三个字段，可以使用下面的SQL语句：

```
-- 预处理parents特征列  
select row_number, value::float8 from aisql.preprocess('parents', 'aisql.nursery', 'nursery.random_forest.classification');  
  
-- 预处理finance特征列  
select row_number, value::float8[] from aisql.preprocess('finance', 'aisql.nursery', 'nursery.random_forest.classification');  
  
-- 预处理class标签列  
select row_number, value::float8 from aisql.preprocess('class', 'aisql.nursery', 'nursery.random_forest.classification');
```

## **自动调参**
自动调参是AutoML的重要环节，用于选择最优的超参数组合，从而提高模型的预测效果。在AiSQL中，自动调参支持网格搜索和随机搜索两种策略，并通过模型训练SQL语句的search、search_params和search_args参数进行指定。
### **网格搜索**
网格搜索是一种通过遍历所有可能的超参数组合，选择最优超参数组合的搜索策略。AiSQL在模型训练SQL语句中，通过设置search参数为'grid'来实施指定算法超参数的网格搜索，并通过search_params参数指定超参数的取值范围。网格搜索忽略search_args参数的设定。
调参示例：
```
-- 针对aisql.nursery表单训练支持向量分类器SVC，并对SVC算法的超参数进行网格搜索，搜索参数为kernel和C，取值范围分别为["linear","poly","rbf","sigmoid"]和[1, 5, 10]  
select aisql.train(project_name=>'nursery.support_vector.classification', task=>'classification', algorithm=>'support_vector', relation_name=>'aisql.nursery', x_column_names=>'{parents,has_nurs,form,children,housing,finance,social,health}'::text[], y_column_names=>'{class}'::text[], preprocess=>'{"_ALL_X_":{"ordinal":{}}, "class":{"encode":{}}}', search=>'grid', search_params=>'{"kernel":["linear","poly","rbf","sigmoid"], "C":[1,5,10]}');
```

### **随机搜索**
随机搜索是一种通过随机生成超参数组合，选择最优超参数组合的搜索策略。AiSQL在模型训练SQL语句中，通过设置search参数为'random'来实施指定算法超参数的随机搜索，并通过search_params参数指定超参数的取值范围。随机搜索支持search_args参数的迭代次数n_iter设定，比如：
```
search_args=>'{"n_iter":10}'
```

### **分类算法的超参数**
AI特性插件支持多种分类算法，包括在各种预测建模大赛中独占鳌头的三大梯度提升树算法xgboost、lightgbm和catboost。下面部分以AiSQL中的算法名作为标题给出对应算法的主要超参数及其说明。
1.xgboost

XGBClassifier (xgboost) 使用梯度提升树模型进行分类。基于梯度提升树模型通过将数据集分成多个子集，然后在每个子集上训练一个决策树，最后将所有决策树的结果进行融合。 
XGBClassifier的常用超参数包括:
（1）max_depth: 整数，默认值为6。树的最大深度。
（2）learning_rate: 浮点数，默认值为0.3。学习率，即每棵树对最终结果的贡献度。
（3）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（4）subsample: 浮点数，默认值为1.0。每棵树训练时使用的样本比例。
（5）colsample_bytree: 浮点数，默认值为1.0。每棵树训练时使用的特征比例。

2.lightgbm
LGBMClassifier (lightgbm) 基于梯度提升树模型，通过迭代地构建多棵树来提高模型的性能。在每次迭代中，它会选择一个最优的分裂点，将数据集分成两部分，然后在这两部分上分别构建左右子树。这个过程会一直进行，直到达到预设的停止条件。
LGBMClassifier的常用超参数包括:

（1）num_leaves: 整数，默认值为31。树的最大叶子节点数。
（2）learning_rate: 浮点数，默认值为0.1。学习率，即每棵树对最终结果的贡献度。
（3）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（4）subsample: 浮点数，默认值为1.0。每棵树训练时使用的样本比例。

3.catboost
CatBoostClassifier (catboost) 通过构建多棵树来学习数据中的模式，并使用这些模式来对新的数据进行分类。每棵树都是一个二叉树，它将数据分成两个子集，直到达到预定的停止条件。catboost使用了基于梯度提升的方法，通过迭代地构建多棵树来提高模型的性能。它是所有分类算法中，唯一一种能够直接处理字符型特征列和标签列的算法，其他分类算法均需要在训练前将字符型特征列和标签列转换为数值型特征列和标签列。
CatBoostClassifier的常用超参数包括:
（1）depth: 整数，默认值为6。树的最大深度。
（2）learning_rate: 浮点数，默认值为0.1。学习率，即每棵树对最终结果的贡献度。
（3）iterations: 整数，默认值为100。树的个数，即迭代次数。

4.decision_tree
决策树分类器DecisionTreeClassifier (decision_tree) 是一种基于贪心算法构建的树形模型，它通过递归地分割数据集来创建树节点。在每个节点上，决策树选择一个最优的特征和阈值来分割数据集，使得分割后的子集尽可能属于同一个类别。这个过程一直进行到所有特征都被使用过，或者数据集中的所有类别都只有一个样本。
DecisionTreeClassifier的常用超参数包括:
（1）max_depth: 整数，默认值为None（设置默认值时不定义max_depth参数）。树的最大深度，其中None表示不限定树的最大深度。
（2）min_samples_split: 整数，默认值为2。节点分裂所需的最小样本数。
（3）min_samples_leaf: 整数，默认值为1。叶子节点所需的最小样本数。
（4）criterion: 字符串，默认值为'gini'。分裂节点的准则，包括'gini'、'entropy'和'log_loss'三种。

5.xgboost_rf

XGBRFClassifier (xgboost_rf) 利用随机森林算法，通过多棵树来拟合数据分布，从而实现分类。随机森林算法通过在训练过程中随机选择特征和样本，来避免过拟合，提高模型的泛化能力。
XGBRFClassifier的常用超参数包括:
（1）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（2）max_depth: 整数，默认值为6。树的最大深度。
（3）min_samples_split: 整数，默认值为2。节点分裂所需的最小样本数。
（4）min_samples_leaf: 整数，默认值为1。叶子节点所需的最小样本数。

6.random_forest
随机森林分类器RandomForestClassifier (random_forest) 是一种集成学习方法，它通过训练多个决策树模型来提高模型的性能。
RandomForestClassifier的常用超参数包括:
（1）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（2）max_depth: 整数，默认值为None（设置默认值时不定义max_depth参数）。树的最大深度，其中None表示不限定树的最大深度。
（3）min_samples_split: 整数，默认值为2。节点分裂所需的最小样本数。
（4）min_samples_leaf: 整数，默认值为1。叶子节点所需的最小样本数。

7.support_vector
支持向量分类器SVC (support_vector) 是一种针对二分类问题来设计的监督学习算法。它通过寻找分类超平面，使得正负样本之间的间隔最大。
SVC的常用超参数包括:
（1）C: 浮点数，默认值为1.0。正则化参数，用于控制模型的复杂度和过拟合程度。
（2）kernel: 字符串，默认值为'rbf'。核函数的类型，包括'linear'、'poly'、'rbf'、'sigmoid'和'precomputed'等。
（3）gamma: 'auto'、'scale'或浮点数，默认值为'auto'。核函数的系数，用于控制核函数的形状。

### **回归算法的超参数**
AI特性插件支持多种回归算法，包括在各种预测建模大赛中独占鳌头的三大梯度提升树算法xgboost、lightgbm和catboost。下面部分以AiSQL中的算法名作为标题给出对应算法的主要超参数及其说明。
1.xgboost
XGBRegressor (xgboost) 基于梯度提升树模型，通过构建多棵树来拟合目标函数。在训练过程中，它会根据损失函数的梯度来更新树的参数，从而逐步逼近目标函数。
XGBRegressor的常用超参数包括:
（1）max_depth: 整数，默认值为6。树的最大深度。
（2）learning_rate: 浮点数，默认值为0.3。学习率，即每棵树对最终结果的贡献度。
（3）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（4）subsample: 浮点数，默认值为1.0。每棵树训练时使用的样本比例。
（5）colsample_bytree: 浮点数，默认值为1.0。每棵树训练时使用的特征比例。

2.lightgbm
LGBMRegressor (lightgbm) 基于梯度提升树模型，通过迭代地构建多棵树来提高模型的性能。在每次迭代中，它会选择一个最优的分裂点，将数据集分成两部分，然后在这两部分上分别构建左右子树。这个过程会一直进行，直到达到预设的停止条件。
LGBMRegressor的常用超参数包括:
（1）num_leaves: 整数，默认值为31。树的最大叶子节点数。
（2）learning_rate: 浮点数，默认值为0.1。学习率，即每棵树对最终结果的贡献度。
（3）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（4）subsample: 浮点数，默认值为1.0。每棵树训练时使用的样本比例。

3.catboost
CatBoostRegressor (catboost) 通过构建多棵树来学习数据中的模式，并使用这些模式来对新的数据进行回归。每棵树都是一个二叉树，它将数据分成两个子集，直到达到预定的停止条件。catboost使用了基于梯度提升的方法，通过迭代地构建多棵树来提高模型的性能。它是所有回归算法中，唯一一种能够直接处理字符型特征列和标签列的算法，其他回归算法均需要在训练前将字符型特征列和标签列转换为数值型特征列和标签列。
CatBoostRegressor的常用超参数包括:
（1）depth: 整数，默认值为6。树的最大深度。
（2）learning_rate: 浮点数，默认值为0.1。学习率，即每棵树对最终结果的贡献度。
（3）iterations: 整数，默认值为100。树的个数，即迭代次数。

4.decision_tree
决策树回归器DecisionTreeRegressor (decision_tree) 是一种基于贪心算法构建的树形模型，它通过递归地分割数据集来创建树节点。在每个节点上，决策树选择一个最优的特征和阈值来分割数据集，使得分割后的子集尽可能属于同一个较小的数值范围。
DecisionTreeRegressor的常用超参数包括:
（1）max_depth: 整数，默认值为None（设置默认值时不定义max_depth参数）。树的最大深度，其中None表示不限定树的最大深度。
（2）min_samples_split: 整数，默认值为2。节点分裂所需的最小样本数。
（3）min_samples_leaf: 整数，默认值为1。叶子节点所需的最小样本数。
（4）criterion: 字符串，默认值为'squared_error'。分裂节点的准则，包括'squared_error'、'friedman_mse'、'absolute_error'和'poisson'四种。
（5）splitter: 字符串，默认值为'best'。分裂节点的策略，包括'best'和'random'两种。

5.xgboost_rf
XGBRFRegressor (xgboost_rf) 利用随机森林算法，通过多棵树来拟合数据分布，从而实现回归。随机森林算法通过在训练过程中随机选择特征和样本，来避免过拟合，提高模型的泛化能力。
XGBRFRegressor的常用超参数包括:
（1）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（2）max_depth: 整数，默认值为6。树的最大深度。
（3）min_samples_split: 整数，默认值为2。节点分裂所需的最小样本数。
（4）min_samples_leaf: 整数，默认值为1。叶子节点所需的最小样本数。

6.random_forest
随机森林回归器RandomForestRegressor (random_forest) 是一种集成学习方法，它通过训练多个决策树模型来提高模型的性能。
RandomForestRegressor的常用超参数包括:
（1）n_estimators: 整数，默认值为100。树的个数，即迭代次数。
（2）max_depth: 整数，默认值为None（设置默认值时不定义max_depth参数）。树的最大深度，其中None表示不限定树的最大深度。
（3）min_samples_split: 整数，默认值为2。节点分裂所需的最小样本数。
（4）min_samples_leaf: 整数，默认值为1。叶子节点所需的最小样本数。

7.support_vector
支持向量回归器SVR (support_vector) 是一种基于支持向量的回归算法，它通过寻找最优的回归超平面来拟合数据。支持向量回归器可以处理非线性回归问题，并且具有较好的泛化能力。
SVR的常用超参数包括:
（1）C: 浮点数，默认值为1.0。正则化参数，用于控制模型的复杂度和过拟合程度。
（2）kernel: 字符串，默认值为'rbf'。核函数的类型，包括'linear'、'poly'、'rbf'、'sigmoid'和'precomputed'等。
（3）gamma: 'auto'、'scale'或浮点数，默认值为'auto'。核函数的系数，用于控制核函数的形状。
（4）epsilon: 浮点数，默认值为0.1。容忍误差，即预测值与真实值之间的最大误差。

### **聚类算法的超参数**
AI特性插件支持数种聚类算法。下面部分以AiSQL中的算法名作为标题给出对应算法的主要超参数及其说明。

1.kmeans
KMeans (kmeans) 是一种基于距离的聚类算法，它通过迭代地优化聚类中心的位置，使得每个样本点到其所属聚类中心的距离之和最小。
KMeans的常用超参数包括:
（1）n_clusters: 整数，默认值为8。聚类的个数。
（2）max_iter: 整数，默认值为300。最大迭代次数。
（3）init: 字符串或数组，默认值为'k-means++'。聚类中心的初始化方法，包括'k-means++'、'random'和(n_clusters, n_features)二维数组。
（4）n_init: 整数，默认值为10。初始化聚类中心的次数，每次初始化都会计算一个聚类结果，最终选择最优的聚类结果。
（5）algorithm: 字符串，默认值为'lloyd'。聚类算法的实现方式，包括'lloyd'和'elkan'两种。

2.mb_kmeans
MiniBatchKMeans (mb_kmeans) 是一种基于KMeans的聚类算法，它通过使用小批量样本来优化聚类中心的位置，从而提高算法的效率。MiniBatchKMeans在每次迭代中，随机选择一个小批量样本，然后使用这些样本来更新聚类中心的位置。
MiniBatchKMeans的常用超参数包括:
（1）n_clusters: 整数，默认值为8。聚类的个数。
（2）batch_size: 整数，默认值为100。每次迭代使用的小批量样本数。
（3）max_iter: 整数，默认值为100。最大迭代次数。
（4）init: 字符串或数组，默认值为'k-means++'。聚类中心的初始化方法，包括'k-means++'、'random'和(n_clusters, n_features)二维数组。
（5）n_init: 整数，默认值为10。初始化聚类中心的次数，每次初始化都会计算一个聚类结果，最终选择最优的聚类结果。

## **自动算法选择**
自动算法选择也是AutoML的重要环节，用于选择最合适的算法，从而提高模型的预测效果。在AiSQL中，自动算法选择通过指定任务内所有算法的5-折交叉验证结果来挑选性能评分最高的算法，并通过在模型训练SQL语句中不指定algorithm参数（即采用algorithm参数的默认空值）的方式来启动指定任务内所有算法的训练过程。自动算法选择的效果体现在模型预测阶段。
下面列出了各个任务在实施交叉验证时采用的性能指标。
**1.分类任务**: 准确率 (accuracy_score)
**2.回归任务**: R方决定稀疏 (r2_score)
**3.聚类任务**: 每个样本到其最近聚类中心的欧式距离的平方和的相反数 (-SSE)

不限定算法的模型训练示例：
```
-- 以aisql.nursery表单作为训练集，启动所有分类算法的训练过程  
select aisql.train(project_name=>'nursery.classification', task=>'classification', relation_name=>'aisql.nursery', x_column_names=>'{parents,has_nurs,form,children,housing,finance,social,health}'::text[], y_column_names=>'{class}'::text[], preprocess=>'{"_ALL_X_":{"ordinal":{}}, "class":{"encode":{}}}');
```

如果需要了解各个任务支持的算法，可以通过下述SQL语句进行查询：
```
select * from aisql.list_algorithms();
```

如果需要找到项目中性能评分最高的算法（简称最优算法），可以通过下述SQL语句进行查询：
```
select * from aisql.get_best_model(project_name text, label_column text default NULL);
```

其中，project_name是需要查询的项目名称，label_name是需要查询的标签列名。项目在训练阶段即使采用相同的算法，也会根据不同的标签列训练不同的模型，因此不同标签列很可能对应不同的性能评分最高的算法。当label_name参数不给定，即采用默认的NULL值时，该SQL语句返回所有标签列对应模型中性能评分最高的模型名称，否则返回指定标签列对应模型中性能评分最高的模型名称。返回的模型名称采用“任务:模型”的形式来表示。
最优模型查询示例：

```
-- 查询训练好的nursery.classification项目中的最优模型  
select aisql.get_best_model('nursery.classification');
```

## **模型预测**
模型预测是机器学习的重要步骤，用于将训练好的模型应用到新的数据上，从而预测新的结果。针对表单数据单条记录，模型预测可以通过下述SQL语句进行：
```
select * from aisql.predict(project_name text, tuple_text text, label_column text default NULL);
```

其中，参数说明如下：
project_name: 字符串，指定项目名称。
tuple_text: 字符串，指定表单数据单条记录的JSON文本表示，格式为{"列名1":值1, "列名2":值2, ... , "列名n":值n}。
label_column: 字符串，指定标签列名，默认为NULL。聚类任务不需要指定标签列名，分类和回归任务需要指定标签列名。在分类或回归任务中，当label_column为NULL时，会自动选择训练时指定的第一个标签列名。

该SQL语句返回一个字符型预测值。聚类和回归任务的预测值原本都是数值，但为了统一返回值类型，预测值被转换为字符串来表示。
当指定项目已经训练好多个预测模型时，该SQL语句会自动选择评分最高的模型进行预测，其中模型的评分是模型在训练期间进行5-折交叉验证得到的性能结果。所有模型在进行交叉验证时会根据各自所属的任务采用不同的性能指标，具体如下：
**1.分类任务**: 准确率 (accuracy_score)
**2.回归任务**: R方决定稀疏 (r2_score)
**3.聚类任务**: 每个样本到其最近聚类中心的欧式距离的平方和的相反数 (-SSE)

模型预测示例：
```
-- 从nursery.classification项目中自动挑选出评分最高的分类模型，以aisql.nursery表单作为测试集预测前10条记录的标签，并与aisql.nursery表单中的标签进行对比  
select class, aisql.predict('nursery.classification', make_json_map(make_kv_array('{parents,has_nurs,form,children,housing,finance,social,health}'::text[], array[parents,has_nurs,form,children,housing,finance,social,health], TRUE)), 'class') from aisql.nursery limit 10;
```

其中，make_json_map函数用于将键值对数组转换为JSON文本表示，make_kv_array函数用于将两个相同元素个数的字符型数组（对应前两个参数）按照对应元素合成键值对数组，第三个参数决定是否对第二个参数中的元素添加双引号，默认值为FALSE。
下面是关于make_json_map函数和make_kv_array函数的一些例子：

```
select make_json_map(make_kv_array(array['a','b','c'], array['1','2','3'], TRUE));   
-- 返回 {"a":"1","b":"2","c":"3"}  
  
select make_json_map(make_kv_array(array['a','b','c'], array['1','2','3'], FALSE));  
-- 返回 {"a":1,"b":2,"c":3}  
  
select make_json_map(make_kv_array(array['a','b','c'], array['1','2','3']));  
-- 返回 {"a":1,"b":2,"c":3}
```

## **批量预测**
为了提高模型预测的效率，可以批量执行针对表单数据的模型预测。使用的SQL语句如下：
```
select * from aisql.batch_predict(project_name text, tuple_text text, label_column text default NULL);
```

其中，参数说明如下：
project_name: 字符串，指定项目名称。
tuple_text: 字符串，指定表单数据多条记录的列式JSON文本表示，格式为{"列名1":[值1,值2,...,值m], "列名2":[值1,值2,...,值m], ... , "列名n":[值1,值2,...,值m]}。
label_column: 字符串，指定标签列名，默认为NULL。聚类任务不需要指定标签列名，分类和回归任务需要指定标签列名。在分类或回归任务中，当label_column为NULL时，会自动选择训练时指定的第一个标签列名。

该SQL语句返回一个字符型的预测值列表。聚类和回归任务的预测值原本都是数值，但为了统一返回值类型，预测值被转换为字符串来表示。
与单条记录的预测一样，当指定项目已经训练好多个预测模型时，该SQL语句会自动选择评分最高的模型进行预测。
批量预测示例：
```
-- 从nursery.classification项目中自动挑选出评分最高的分类模型，以aisql.nursery表单作为测试集批量预测前10条记录的标签，并与aisql.nursery表单中的标签进行对比  
select unnest(array_agg(class)), unnest(aisql.batch_predict('nursery.classification', make_json_map(make_kv_ext_array('{parents, has_nurs, form, children, housing, finance, social, health}'::text[], array[array_agg(parents), array_agg(has_nurs), array_agg(form), array_agg(children), array_agg(housing), array_agg(finance), array_agg(social), array_agg(health)], TRUE)))) from aisql.nursery limit 10;
```

其中，make_kv_ext_array函数用于将多个相同元素个数的数组（对应前两个参数）按照对应元素合成键值对数组，第一个参数是字符型数组，第二个参数是字符型数组的数组，第三个参数决定是否对第二个参数中的元素添加双引号，默认值为FALSE。
下面是关于make_kv_ext_array函数的一些例子：
```
select make_json_map(make_kv_ext_array(array['a','b','c'], array[array['1','2','3'], array['4','5','6'], array['7','8','9']], TRUE));  
-- 返回 {"a":["1","2","3"],"b":["4","5","6"],"c":["7","8","9"]}  
  
select make_json_map(make_kv_ext_array(array['a','b','c'], array[array['1','2','3'], array['4','5','6'], array['7','8','9']]));  
-- 返回 {"a":[1,2,3],"b":[4,5,6],"c":[7,8,9]}
```

## **模型评估**
模型评估也是机器学习的重要步骤，用于评估模型在测试集上的表现。针对表单数据形式的测试集，模型评估可以通过下述SQL语句进行：
```
select * from aisql.evaluate(project_name text, relation_name text, label_column text, metric_names text[]);
```

其中，参数说明如下：
project_name: 字符串，指定项目名称。
relation_name: 字符串，指定表单数据表名，用作测试集。
label_column: 字符串，指定标签列名。聚类任务采用外部指标评估，因此也需要提供标签列名。
metric_names: 字符串数组，指定多个评估指标名称。

该SQL语句的返回值是一个数据视图，由(任务:模型，标签列名，评分)三个字段的记录构成，每条记录对应指定项目构建的一个模型在指定测试集上的评估结果。
下面列举不同任务所支持的评估指标，这些指标也可以通过下述SQL语句列出来。
```
-- 列出分类任务支持的所有评估指标  
select aisql.list_classification_metrics();  
  
-- 列出回归任务支持的所有评估指标  
select aisql.list_regression_metrics();  
  
-- 列出聚类任务支持的所有评估指标  
select aisql.list_clustering_metrics();
```

**1.分类任务**
accuracy_score: 准确率，表示模型正确分类的样本数量与总样本数量之间的比值
balanced_accuracy_score: 平衡准确率，它是准确率的一种改进版本，可以更好地处理类别不平衡的数据
brier_score_loss: Brier分数损失，用于评估概率预测的质量
cohen_kappa_score: 科恩卡帕分数，用于衡量预测结果和实际结果的一致性
matthews_corrcoef: Matthews相关系数，通过计算真阳性、假阳性、真阴性和假阴性的数量，汇总评估分类模型性能
precision_score: 精确率，又称查准率，处理多分类问题时等价于精确率微平均值
recall_score: 召回率，又称查全率，处理多分类问题时等价于召回率微平均值- - f1_score: F1分数，处理多分类问题时等价于F1分数微平均值
zero_one_loss: 零一损失，表示模型错误分类的样本数量与总样本数量之间的比值
macro_precision: 精确率宏平均值，即每个标签的精确率的平均值
macro_recall: 召回率宏平均值，即每个标签的召回率的平均值
macro_f1: F1分数宏平均值，即每个标签的F1分数的平均值
macro_auc: AUC宏平均值，即每个标签的AUC的平均值
micro_precision: 精确率微平均值，即通过总的真实正例、假负例和假正例来全局计算的精确率
micro_recall: 召回率微平均值，即通过总的真实正例、假负例和假正例来全局计算的召回率
micro_f1: F1分数微平均值，即通过总的真实正例、假负例和假正例来全局计算的F1分数

**2.回归任务**
d2_absolute_error_score：D^2绝对误差分数，用于衡量模型预测与实际值之间的差异
d2_pinball_score：D^2 Pinball分数，采用Pinball损失函数来衡量模型预测与实际值之间的差异
explained_variance_score：解释方差分数，用于衡量模型解释的方差占实际方差的比例
max_error：最大误差，用于衡量模型预测与实际值之间的最大差异
mean_absolute_error：平均绝对误差，用于衡量模型预测与实际值之间的平均差异
mean_absolute_percentage_error：平均绝对百分比误差，用于衡量模型预测与实际值之间的平均差异，其中百分比误差是指实际值与预测值之间的差异占实际值的百分比
mean_gamma_deviance：平均伽马偏差，采用伽马损失函数来衡量模型预测与实际值之间的差异
mean_pinball_loss：平均Pinball损失，采用Pinball损失函数来衡量模型预测与实际值之间的差异
mean_poisson_deviance：平均泊松偏差，采用泊松损失函数来衡量模型预测与实际值之间的差异
mean_squared_error：均方误差，用于衡量模型预测与实际值之间的差异，其中平方误差是指实际值与预测值之间的平方差
mean_squared_log_error：均方对数误差，用于衡量模型预测与实际值之间的差异，其中对数误差是指实际值与预测值之间的对数差。
mean_tweedie_deviance：平均Tweedie偏差，采用Tweedie损失函数来衡量模型预测与实际值之间的差异
median_absolute_error：中位数绝对误差，用于衡量模型预测与实际值之间的差异，其中中位数是指实际值与预测值之间的中位数差异。
r2_score：R^2 分数，用于衡量模型解释的方差占实际方差的比例的指标，其中 R^2 是指模型解释的方差与实际方差的比值。

**3.聚类任务**
adjusted_mutual_info_score：调整互信息分数，通过计算两个聚类结果之间的互信息，然后减去期望的互信息来消除随机性
adjusted_rand_score：调整兰德分数，通过计算两个聚类结果之间的兰德系数，然后减去期望的兰德系数来消除随机性
completeness_score：完整性分数，通过计算聚类结果与真实标签之间的相似度来衡量
fowlkes_mallows_score：Fowlkes-Mallows分数，通过计算两个聚类结果之间的Fowlkes-Mallows系数来衡量
homogeneity_score：同质性分数，通过计算聚类结果与真实标签之间的相似度来衡量
mutual_info_score：互信息分数，通过计算两个聚类结果之间的互信息来衡量
normalized_mutual_info_score：归一化互信息分数，通过计算两个聚类结果之间的归一化互信息来衡量
rand_score：兰德分数，通过计算两个聚类结果之间的兰德系数来衡量
v_measure_score：V-measure分数，通过计算聚类结果与真实标签之间的V-measure系数来衡量

模型评估示例：
```
-- 将aisql.nursery表单作为测试集，评估nursery.classification项目中所有分类模型的性能，包括准确率、平衡准确率、科恩卡帕分数和F1分数  
select * from aisql.evaluate('nursery.classification', 'aisql.nursery', 'class', '{accuracy_score,balanced_accuracy_score,cohen_kappa_score,f1_score}'::text[]);
```

## **模型查询**
对于训练好的项目，可以通过下述SQL语句查询项目中的模型信息。
```
select * from aisql.list_models(project_name text default NULL);
```

其中，project_name是可选参数，指定要查询的项目名称。如果不指定，则查询所有项目中的模型信息。返回值是一个数据视图，由(项目名，训练表单名，标签列名，任务:模型，模型超参数，字段预处理定义，评分)七个字段的记录构成，每条记录对应一个模型的信息。
模型查询示例：
```
-- 查询nursery.classification项目中所有分类模型的性能  
select * from aisql.list_models('nursery.classification');
```

## **模型删除**
对于训练好的项目，可以通过下述SQL语句删除项目中针对指定标签列、由指定算法训练得到的模型。
```
select * from aisql.remove_model(project_name text, algorithm text, label_column text default NULL);
```

其中，project_name是要删除模型的项目名称，algorithm是待删除模型对应的训练算法，label_column是可选参数，指定待删除模型的标签列。若label_name不指定，即默认为NULL值，则该SQL语句删除指定项目中由指定算法训练得到的所有模型；换句话说，待删除的模型不依赖于标签列。该SQL语句返回模型删除的响应信息。若删除成功，则响应"Done"，否则根据具体情况，响应指定项目不存在，或指定标签列不属于指定项目，或指定算法在指定项目中不存在等错误信息。