

以下示例说明了如何使用BMDB及其生态系统集成（包括Apache Spark、Apache Kafka、Spring Boot和KairosDB）构建真实的端到端应用程序。

## **物联网车辆管理应用程序**


### **概述**

物联网车辆管理是一个端到端的功能应用程序，其源代码和安装说明可在GitLab上获得。它是在BMDB（使用Cassandra兼容的BCQL API）作为数据库，Confluent Kafka作为消息代理，KSQL或Apache Spark Streaming用于实时分析，Spring Boot作为应用框架的基础上构建的物联网应用程序的蓝图。

### **场景**

假设车辆管理公司希望跟踪其运送货物的车辆。进行运输的车辆有不同的类型（18轮式、公共汽车、大型卡车等），运输本身通过3条路线（37号路线、82号路线、43号路线）进行。该公司希望跟踪：

* 每个装运交付路线的车辆类型明细
* 哪些车辆接近封路，以便预测交付延迟
  此应用程序会呈现一个仪表板，显示上述两项。下面是实时、自动刷新的仪表板视图。

![](../assets/chapter3/19.png)

### **应用程序体系结构**

此应用程序包含以下子组件：

* Data Store-BMDB，用于存储Kafka的原始事件以及数据处理器的聚合。
* Data Producer-将测试程序写入Kafka
* Data Processor-从Kafka读取KSQL或Apache Spark流，计算聚合并将结果存储在数据存储中
* Data Dashboard-使用web套接字、jQuery和bootstrap的Spring Boot应用程序

我们将详细研究这些组件中的每一个。下面是一个体系结构图，显示了这些组件是如何组合在一起的

#### **Confluent Kafka, KSQL, 与BMDB(CKY Stack)**

CKY堆栈的应用程序架构如下所示。BMDB的相同Kafka Connect Sink连接器用于存储原始事件和聚合数据（使用KSQL生成）。


![](../assets/chapter3/20.png)

#### **Spark, Kafka, 与BMDB(SKY Stack)**

带有SKY堆栈的应用程序架构如下所示。BMDB的Kafka Connect Sink连接器用于存储从Kafka到BMDB的原始事件。通过Apache Spark Streaming生成的聚合数据使用Spark Cassandra连接器持久化在BMDB中。

![](../assets/chapter3/21.png)

### **Data store**

存储所有面向用户的数据。这里使用的是BMDB，编程语言是与Cassandra兼容的BCQL。
所有数据都存储在密钥空间TrafficKeySpace中：

```
CREATE KEYSPACE IF NOT EXISTS TrafficKeySpace
```

有一个表用于存储原始事件。请注意下面的default_time_to_live值，以确保原始事件在指定的时间段后自动过期。这是为了确保原始事件不会占用数据库中的所有存储，并在计算其聚合后的短时间内有效地从数据库中删除。

```
CREATE TABLE TrafficKeySpace.Origin_Table (
  vehicleId text,
  routeId text,
  vehicleType text,
  longitude text,
  latitude text,
  timeStamp timestamp,
  speed double,
  fuelLevel double,
PRIMARY KEY ((vehicleId), timeStamp))
WITH default_time_to_live = 3600;
```

有三个表保存面向用户的数据——Total_Traffic用于交通信息生命周期，Window_Traffics用于最后30秒的交通，poi_Traffic则用于兴趣点附近的交通（道路封闭）。数据处理器不断更新这些表，仪表板从这些表中读取数据。以下是这些表的模式。


```
CREATE TABLE TrafficKeySpace.Total_Traffic (
    routeId text,
    vehicleType text,
    totalCount bigint,
    timeStamp timestamp,
    recordDate text,
    PRIMARY KEY (routeId, recordDate, vehicleType)
);
 
CREATE TABLE TrafficKeySpace.Window_Traffic (
    routeId text,
    vehicleType text,
    totalCount bigint,
    timeStamp timestamp,
    recordDate text,
    PRIMARY KEY (routeId, recordDate, vehicleType)
);
 
CREATE TABLE TrafficKeySpace.poi_traffic(
    vehicleid text,
    vehicletype text,
    distance bigint,
    timeStamp timestamp,
    PRIMARY KEY (vehicleid)
);
```


### **Data producer**

一个生成随机测试数据并将其发布到Kafka主题 iot-data-event的程序。这模拟了在现实世界中使用消息代理从连接的车辆接收的数据。

单个数据点是一个JSON有效负载，如下所示：


```
{
  "vehicleId":"0bf45cac-d1b8-4364-a906-980e1c2bdbcb",
  "vehicleType":"Taxi",
  "routeId":"Route-37",
  "longitude":"-95.255615",
  "latitude":"33.49808",
  "timestamp":"2017-10-16 12:31:03",
  "speed":49.0,
  "fuelLevel":38.0
}
```

BMDB的Kafka Connect Sink连接器读取上述iot-data-event主题，将事件转换为BCQL INSERT语句，然后调用BMDB将事件持久化到TrafficKeySpace.Origin_Table表中。

### **Data processor**

#### **KSQL**

KSQL是Apache Kafka的开源流式SQL引擎。它为Kafka上的流处理提供了一个易于使用但功能强大的交互式SQL接口，无需使用Java或Python等编程语言编写代码。它支持广泛的流操作，包括数据过滤、转换、聚合、联接、窗口和会话。
使用KSQL的第一步是根据原始事件创建流，如下所示。

```
CREATE STREAM traffic_stream (
           vehicleId varchar,
           vehicleType varchar,
           routeId varchar,
           timeStamp varchar,
           latitude varchar,
           longitude varchar)
    WITH (
           KAFKA_TOPIC='iot-data-event',
           VALUE_FORMAT='json',
           TIMESTAMP='timeStamp',
           TIMESTAMP_FORMAT='yyyy-MM-dd HH:mm:ss');
```

现在可以在上面的流上运行各种聚合/查询，每种类型的查询的结果都存储在自己的主题中。此应用程序使用3个这样的查询/主题。之后，BMDB的Kafka Connect Sink连接器读取这3个主题，并将结果保存到BMDB数据库中的3个相应表中。


```
CREATE TABLE total_traffic
     WITH ( PARTITIONS=1,
            KAFKA_TOPIC='total_traffic',
            TIMESTAMP='timeStamp',
            TIMESTAMP_FORMAT='yyyy-MM-dd HH:mm:ss') AS
     SELECT routeId,
            vehicleType,
            count(vehicleId) AS totalCount,
            max(rowtime) AS timeStamp,
            TIMESTAMPTOSTRING(max(rowtime), 'yyyy-MM-dd') AS recordDate
     FROM traffic_stream
     GROUP BY routeId, vehicleType;
CREATE TABLE window_traffic
     WITH ( TIMESTAMP='timeStamp',
            KAFKA_TOPIC='window_traffic',
            TIMESTAMP_FORMAT='yyyy-MM-dd HH:mm:ss',
            PARTITIONS=1) AS
     SELECT routeId,
            vehicleType,
            count(vehicleId) AS totalCount,
            max(rowtime) AS timeStamp,
            TIMESTAMPTOSTRING(max(rowtime), 'yyyy-MM-dd') AS recordDate
     FROM traffic_stream
     WINDOW HOPPING (SIZE 30 SECONDS, ADVANCE BY 10 SECONDS)
     GROUP BY routeId, vehicleType;
CREATE STREAM poi_traffic
      WITH ( PARTITIONS=1,
             KAFKA_TOPIC='poi_traffic',
             TIMESTAMP='timeStamp',
             TIMESTAMP_FORMAT='yyyy-MM-dd HH:mm:ss') AS
      SELECT vehicleId,
             vehicleType,
             cast(GEO_DISTANCE(cast(latitude AS double),cast(longitude AS double),33.877495,-95.50238,'KM') AS bigint) AS distance,
             timeStamp
      FROM traffic_stream
      WHERE GEO_DISTANCE(cast(latitude AS double),cast(longitude AS double),33.877495,-95.50238,'KM') < 30;
```

#### **Apache Spark streaming**

作为KSQL的替代方案，您可以使用Apache Spark，这是一种用于在单节点机器或集群上执行数据工程、数据科学和机器学习的多语言引擎。
下面是一个示例Apache Spark流应用程序（Java），它使用Kafka主题的数据流，将其转换为有意义的见解，并通过DataStax Spark Cassandra连接器将生成的聚合数据写入BMDB。
设置Spark Cassandra连接器：

```
SparkConf conf = new SparkConf()
                   .setAppName(prop.getProperty("com.iot.app.spark.app.name"))
                   .setMaster(prop.getProperty("com.iot.app.spark.master"))
                   .set("spark.cassandra.connection.host", cassandraHost)
                   .set("spark.cassandra.connection.port", cassandraPort)
                   .set("spark.cassandra.connection.keep_alive_ms", prop.getProperty("com.iot.app.cassandra.keep_alive"));
```

数据是从Kafka流中消耗的，分5秒收集：

```
JavaStreamingContext jssc = new JavaStreamingContext(conf, Durations.seconds(5));
 
JavaPairInputDStream<String, IoTData> directKafkaStream =
  KafkaUtils.createDirectStream(jssc,
                                String.class,
                                IoTData.class,
                                StringDecoder.class,
                                IoTDataDecoder.class,
                                kafkaParams,
                                topicsSet
                               );
```

创建未过滤和过滤的流，稍后在实际处理中使用：

```
// Non-filtered stream for Point-of-interest (POI) traffic data calculation
JavaDStream<IoTData> nonFilteredIotDataStream = directKafkaStream.map(tuple -> tuple._2());
 
// Filtered stream for total and traffic data calculation
JavaPairDStream<String,IoTData> iotDataPairStream =
  nonFilteredIotDataStream.mapToPair(iot -> new Tuple2<String,IoTData>(iot.getVehicleId(),iot)).reduceByKey((a, b) -> a );
 
// Check vehicle ID is already processed
JavaMapWithStateDStream<String, IoTData, Boolean, Tuple2<IoTData,Boolean>> iotDStreamWithStatePairs =
  iotDataPairStream.mapWithState(
    StateSpec.function(processedVehicleFunc).timeout(Durations.seconds(3600)) // Maintain state for one hour
  );
 
// Filter processed vehicle IDs and keep un-processed
JavaDStream<Tuple2<IoTData,Boolean>> filteredIotDStreams =
  iotDStreamWithStatePairs.map(tuple2 -> tuple2).filter(tuple -> tuple._2.equals(Boolean.FALSE));
 
// Get stream of IoTData
JavaDStream<IoTData> filteredIotDataStream = filteredIotDStreams.map(tuple -> tuple._1);
```

上述代码使用以下功能检查是否有经过处理的车辆：

```
Function3<String, Optional<IoTData>, State<Boolean>, Tuple2<IoTData, Boolean>> processedVehicleFunc = (String, iot, state) -> {
  Tuple2<IoTData,Boolean> vehicle = new Tuple2<>(iot.get(), false);
  if (state.exists()) {
    vehicle = new Tuple2<>(iot.get(), true);
  }
  else {
    state.update(Boolean.TRUE);
  }
  return vehicle;
};
```

按车辆类型和迄今为止完成的所有车辆和货物的运输路线计算细分：

```
// Get count of vehicle group by routeId and vehicleType
JavaPairDStream<AggregateKey, Long> countDStreamPair =
  filteredIotDataStream
    .mapToPair(iot -> new Tuple2<>(new AggregateKey(iot.getRouteId(), iot.getVehicleType()), 1L))
    .reduceByKey((a, b) -> a + b);
 
// Keep state for total count
JavaMapWithStateDStream<AggregateKey, Long, Long, Tuple2<AggregateKey, Long>> countDStreamWithStatePair =
  countDStreamPair.mapWithState(
    StateSpec.function(totalSumFunc).timeout(Durations.seconds(3600)) // Maintain state for one hour
  );
 
// Transform to DStream of TrafficData
JavaDStream<Tuple2<AggregateKey, Long>> countDStream = countDStreamWithStatePair.map(tuple2 -> tuple2);
JavaDStream<TotalTrafficData> trafficDStream = countDStream.map(totalTrafficDataFunc);
 
// Map Cassandra table column
Map<String, String> columnNameMappings = new HashMap<String, String>();
columnNameMappings.put("routeId", "routeid");
columnNameMappings.put("vehicleType", "vehicletype");
columnNameMappings.put("totalCount", "totalcount");
columnNameMappings.put("timeStamp", "timestamp");
columnNameMappings.put("recordDate", "recorddate");
 
// Call CassandraStreamingJavaUtil function to save in database
javaFunctions(trafficDStream)
  .writerBuilder("traffickeyspace", "total_traffic", CassandraJavaUtil.mapToRow(TotalTrafficData.class, columnNameMappings))
  .saveToCassandra();
```


计算活动装运的相同细分。这是通过计算最后30秒按车辆类型和运输路线划分的细分来完成的：

```
// Reduce by key and window (30 sec window and 10 sec slide)
JavaPairDStream<AggregateKey, Long> countDStreamPair =
  filteredIotDataStream
    .mapToPair(iot -> new Tuple2<>(new AggregateKey(iot.getRouteId(), iot.getVehicleType()), 1L))
    .reduceByKeyAndWindow((a, b) -> a + b, Durations.seconds(30), Durations.seconds(10));
 
// Transform to DStream of TrafficData
JavaDStream<WindowTrafficData> trafficDStream = countDStreamPair.map(windowTrafficDataFunc);
 
// Map Cassandra table column
Map<String, String> columnNameMappings = new HashMap<String, String>();
columnNameMappings.put("routeId", "routeid");
columnNameMappings.put("vehicleType", "vehicletype");
columnNameMappings.put("totalCount", "totalcount");
columnNameMappings.put("timeStamp", "timestamp");
columnNameMappings.put("recordDate", "recorddate");
 
// Call CassandraStreamingJavaUtil function to save in database
javaFunctions(trafficDStream)
  .writerBuilder("traffickeyspace", "window_traffic", CassandraJavaUtil.mapToRow(WindowTrafficData.class, columnNameMappings))
  .saveToCassandra();
```

检测给定点（POI）20英里半径范围内的车辆，表示道路封闭：

```
// Filter by routeId, vehicleType and in POI range
JavaDStream<IoTData> iotDataStreamFiltered =
  nonFilteredIotDataStream
    .filter(iot -> (iot.getRouteId().equals(broadcastPOIValues.value()._2())
                    && iot.getVehicleType().contains(broadcastPOIValues.value()._3())
                    && GeoDistanceCalculator.isInPOIRadius(
                         Double.valueOf(iot.getLatitude()),
                         Double.valueOf(iot.getLongitude()),
                         broadcastPOIValues.value()._1().getLatitude(),
                         broadcastPOIValues.value()._1().getLongitude(),
                         broadcastPOIValues.value()._1().getRadius()
                       )
                   )
    );
 
// Pair with POI
JavaPairDStream<IoTData, POIData> poiDStreamPair =
  iotDataStreamFiltered.mapToPair(iot -> new Tuple2<>(iot, broadcastPOIValues.value()._1()));
 
// Transform to DStream of POITrafficData
JavaDStream<POITrafficData> trafficDStream = poiDStreamPair.map(poiTrafficDataFunc);
 
// Map Cassandra table column
Map<String, String> columnNameMappings = new HashMap<String, String>();
columnNameMappings.put("vehicleId", "vehicleid");
columnNameMappings.put("distance", "distance");
columnNameMappings.put("vehicleType", "vehicletype");
columnNameMappings.put("timeStamp", "timestamp");
 
// Call CassandraStreamingJavaUtil function to save in database
javaFunctions(trafficDStream)
  .writerBuilder("traffickeyspace", "poi_traffic", CassandraJavaUtil.mapToRow(POITrafficData.class, columnNameMappings))
  .withConstantTTL(120) // Keeping data for 2 minutes
  .saveToCassandra();
```

上述“半径内检测”代码使用以下辅助函数：

```
// Function to get running sum by maintaining the state
Function3<AggregateKey, Optional<Long>, State<Long>, Tuple2<AggregateKey, Long>> totalSumFunc = (key, currentSum, state) -> {
  long totalSum = currentSum.or(0L) + (state.exists() ? state.get() : 0);
  Tuple2<AggregateKey, Long> total = new Tuple2<>(key, totalSum);
  state.update(totalSum);
  return total;
};
 
// Function to create TotalTrafficData object from IoT data
Function<Tuple2<AggregateKey, Long>, TotalTrafficData> totalTrafficDataFunc = (tuple -> {
  TotalTrafficData trafficData = new TotalTrafficData();
  trafficData.setRouteId(tuple._1().getRouteId());
  trafficData.setVehicleType(tuple._1().getVehicleType());
  trafficData.setTotalCount(tuple._2());
  trafficData.setTimeStamp(new Date());
  trafficData.setRecordDate(new SimpleDateFormat("yyyy-MM-dd").format(new Date()));
  return trafficData;
});
 
// Function to create WindowTrafficData object from IoT data
Function<Tuple2<AggregateKey, Long>, WindowTrafficData> windowTrafficDataFunc = (tuple -> {
  WindowTrafficData trafficData = new WindowTrafficData();
  trafficData.setRouteId(tuple._1().getRouteId());
  trafficData.setVehicleType(tuple._1().getVehicleType());
  trafficData.setTotalCount(tuple._2());
  trafficData.setTimeStamp(new Date());
  trafficData.setRecordDate(new SimpleDateFormat("yyyy-MM-dd").format(new Date()));
  return trafficData;
});
 
// Function to create POITrafficData object from IoT data
Function<Tuple2<IoTData, POIData>, POITrafficData> poiTrafficDataFunc = (tuple -> {
  POITrafficData poiTraffic = new POITrafficData();
  poiTraffic.setVehicleId(tuple._1.getVehicleId());
  poiTraffic.setVehicleType(tuple._1.getVehicleType());
  poiTraffic.setTimeStamp(new Date());
  double distance = GeoDistanceCalculator.getDistance(
    Double.valueOf(tuple._1.getLatitude()).doubleValue(),
    Double.valueOf(tuple._1.getLongitude()).doubleValue(),
    tuple._2.getLatitude(),
    tuple._2.getLongitude()
  );
  poiTraffic.setDistance(distance);
  return poiTraffic;
});
```

### **Data dashboard**

这是一个Spring Boot应用程序，它从BMDB查询数据，并使用Web Sockets和jQuery将数据推送到网页。数据以固定的时间间隔推送到网页，因此数据将自动刷新。仪表板以图表和表格的形式显示数据。此网页使用bootstrap.js显示包含图表的仪表板。
我们为三个表Total_Traffic、Window_Traffic和Poi_Traffic创建实体类，并为所有扩展CassandraRepository的实体创建DAO接口。例如，您为TotalTrafficData 实体创建DAO类，如下所示。

```
@Repository
public interface TotalTrafficDataRepository extends CassandraRepository<TotalTrafficData> {
  @Query("SELECT * FROM traffickeyspace.total_traffic WHERE recorddate = ? ALLOW FILTERING")
  Iterable<TotalTrafficData> findTrafficDataByDate(String date);
}
```

为了连接到BMDB集群并获得数据库操作的连接，您编写了CassandraConfig 类。具体操作如下：

```
public class CassandraConfig extends AbstractCassandraConfiguration {
  @Bean
  public CassandraClusterFactoryBean cluster() {
    // Create a Cassandra cluster to access BrightDB using CQL.
    CassandraClusterFactoryBean cluster = new CassandraClusterFactoryBean();
    // Set the database host.
    cluster.setContactPoints(environment.getProperty("com.iot.app.cassandra.host"));
    // Set the database port.
    cluster.setPort(Integer.parseInt(environment.getProperty("com.iot.app.cassandra.port")));
    return cluster;
  }
}
 
```


请注意，当前仪表板不使用原始事件表，仅依赖于存储在聚合表中的数据。

### **总结**

该应用程序是构建物联网应用程序的蓝图。构建和运行应用程序的说明以及源代码可以在物联网车辆管理GitLab存储库中找到。