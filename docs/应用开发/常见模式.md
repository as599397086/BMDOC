

BMDB是一个分布式数据库，通过BSQL和BCQL API提供数据访问。尽管它支持这些复杂的API，但它下面是一个NoSQL存储。这使得BMDB自然适合于时间序列、键值和宽列等多种数据模型。
以下部分介绍了如何利用通用数据模型来设计健壮高效的应用程序。

### **概述**

#### 时间序列数据

时间序列数据模型满足了大型事件数据场景对保留事件排序和海量存储的特殊需求。时间序列实际上是按时间排序的一系列事件或消息。事件数据可以是可变大小的，BMDB可以出色地处理大量数据。在BMDB中，数据被排序并按顺序写入磁盘。当按行键然后按范围检索数据时，由于磁盘寻道次数最少，因此可以获得快速高效的访问模式。时间序列数据非常适合这种类型的模式。
一个很好的示例是汽车中的速度传感器，它可以跟踪汽车的速度并将数据发送到远程系统进行跟踪。

```
"car1" , "2023-05-01 01:00:00", 35
"car1" , "2023-05-01 01:01:00", 40
"car1" , "2023-05-01 01:02:00", 42
"car2" , "2023-05-06 01:00:00", 60
"car2" , "2023-05-06 01:01:00", 65
"car2" , "2023-05-06 01:01:00", 70
```

保险公司可以使用这些数据来调查事故，或者汽车公司可以跟踪各种传感器并提高汽车的性能。这可能相当于数十亿个数据点。

有关在BMDB中存储和检索如此大量有序数据的更多信息，请参阅[时间序列数据模型](#_时间序列) 

#### **键值**

在键值数据模型中，每个键都与一个且仅与一个值相关联。BMDB内部将数据存储为键值对的集合，因此自动成为键值存储。
因为在键值存储中，每个键只有一个值，所以键通常被定义为多个参数的组合。例如，为了存储用户的详细信息，可以采用以下模式：

```
user1.name = "John Wick"
user1.country = "CN"
user2.name = "Harry Potter"
user2.country = "UK"
```

关键值存储有望成为一些速度最快的存储数据模型。有关将BMDB用于键值存储的更多信息，请参阅[键值数据模型](#_键值_1)。

#### **宽列**

在宽列数据模型中，数据被组织为行和列。每一行由行id或名称标识，每一列由列id或名称识别。每一行可以附加任意数量的列。您可以将其可视化为一个类似表格的结构，其中一些单元格为空。例如：

```
|       | col-1 | col-2 | col-3 |
| ----- | ----- | ----- | ----- |
| row-1 | a     |       | c     |
| row-2 | e     | f     | g     |
| row-3 | z     |       |       |
```

要检索特定单元格，可以发出类似于以下命令的命令：

```
get(row-1, col-3) ==> c
get(row-3, col-2) ==> NULL
```

 

### **时间序列**

时间序列数据是随着时间的推移而被跟踪和监控的测量值或事件。这可能是服务器指标、应用程序性能监控、网络数据、传感器数据、事件、点击、市场交易以及许多其他类型的分析数据。时间序列数据模型是专门为处理按时间排序的大量数据而设计的。
尽管BMDB默认情况下是哈希分片的，但它也支持范围分片，即在特定边界对数据进行排序和分割。
时间序列模式最适用于需要查找给定时间范围内的范围查询。
您可以使用以下常见模式以分布式和有序的方式，在BMDB中存储和检索时间序列数据： 

* 按时间排序的订单
  在这种模式中，您的所有数据都是按时间在不同的分片上排序的。
  要了解如何以这种模式高效地存储和检索数据，请参阅按时间全局排序。
* 按每个实体的时间排序
  在这种模式中，数据在特定实体中按时间排序。
  要了解如何有效地分发实体并避免热分片，请参阅按每个实体的时间排序。 
* 自动数据过期
  在某些情况下，您不希望数据长期存在，因为这些数据可能不需要，或者您的组织中有规则规定，您不能存储超过特定持续时间的特定数据。对于这种情况，可以对行、列和表本身设置生存时间值。
  有关更多详细信息，请参阅自动数据过期。
* 分区
  当你有很多数据需要定期删除时，你可以选择对数据进行分区。在某些情况下，这也具有速度优势。
  有关更多详细信息，请参阅按时间分区。

#### **按时间排序的订单**

了解如何通过分片来分布整个时间排序数据集，并高效检索数据。

1. 基于时间戳的分布
   考虑一个速度指标跟踪系统，它跟踪来自许多汽车的速度传感器的数据。

创建一个具有示例架构的表，如下所示：

```
CREATE TABLE global_order1 (
    ts timestamp, /* time at which the event was generated */
    car varchar, /* name of the car */
    speed int, /* speed of your car */
    PRIMARY KEY(ts ASC)
);
```

global_order1表存储不同车辆到达时的速度数据点。

在表中插入一些样本数据，如下所示：

```
INSERT INTO global_order1 (ts, car, speed)
        (SELECT '2023-07-01 00:00:00'::timestamp + make_interval(secs=>id),
            'car-' || ceil(random()*2), ceil(random()*60)
            FROM generate_series(1,100) AS id);
```

从表中检索一些数据，如下所示： 

```
SELECT * FROM global_order1;
         ts          |  car  | speed
---------------------+-------+-------
 2023-07-01 00:00:01 | car-1 |    50
 2023-07-01 00:00:02 | car-2 |    25
 2023-07-01 00:00:03 | car-1 |    39
 2023-07-01 00:00:04 | car-1 |    49
 2023-07-01 00:00:05 | car-2 |     3
 2023-07-01 00:00:06 | car-2 |    22
 2023-07-01 00:00:07 | car-2 |    25
 2023-07-01 00:00:08 | car-1 |    58
 2023-07-01 00:00:09 | car-2 |    55
```

请注意数据是如何按时间自动排序的。这是因为表被设置为按PRIMARY KEY（ts ASC）在ts上排序。这样可以确保数据经过排序，并且附近的所有数据都位于同一分片中。此顺序使范围查询能够高效地检索特定时间范围内的所有数据。例如：

```
SELECT * FROM global_order1 WHERE ts > '2023-07-01 00:01:00' AND ts < '2023-07-01 00:01:05';
         ts          |  car  | speed
---------------------+-------+-------
 2023-07-01 00:01:01 | car-1 |    21
 2023-07-01 00:01:02 | car-2 |    58
 2023-07-01 00:01:03 | car-1 |    57
 2023-07-01 00:01:04 | car-2 |    60
```

随着数据量的增长，分片会进行拆分，并将一半数据移动到不同的分片，从而确保可扩展性。这也意味着数据在移动到下一个分片之前会在一个分片中增长。然而，由于特定范围可能在单个分片中，这可能导致一个分片成为热分片。

2. 基于bucket的分配
   要在不同的分片上分发有序的数据，可以使用基于存储bucket的分发，将数据拆分为存储bucket，然后进行分发。
   要做到这一点，请修改表以包括一个值范围很小的bucketid字段，然后分发bucket。例如：

```
CREATE TABLE global_order2 (
    ts timestamp,/* time at which the event was generated */
    car varchar, /* name of the car */
    speed int,   /* speed of your car */
    bucketid smallint DEFAULT random()*8, /* bucket id*/
    PRIMARY KEY(bucketid HASH, ts ASC)
) SPLIT INTO 3 TILES;
```

这将向数据中添加一个bucketid，该bucketid由0到7之间的随机数组成，用于在整体和bucketid上分发数据。

将上面相同的数据添加到新表中，如下所示：

```
INSERT INTO global_order2 (ts, car, speed)
        (SELECT '2023-07-01 00:00:00'::timestamp + make_interval(secs=>id),
            'car-' || ceil(random()*2), ceil(random()*60)
            FROM generate_series(1,100) AS id);
```

 


因为bucketid的默认值设置为random()*8，所以不必显式插入该值。

从表中检索数据，如下所示： 

```
SELECT *, bm_hash_code(bucketid) % 3 as tile FROM global_order2;
         ts          |  car  | speed | bucketid | tile
---------------------+-------+-------+----------+--------
 2023-07-01 00:00:24 | car-2 |    19 |        4 |      2
 2023-07-01 00:00:25 | car-1 |    21 |        4 |      2
 2023-07-01 00:00:26 | car-1 |    40 |        4 |      2
...
 2023-07-01 00:00:35 | car-1 |    46 |        0 |      1
 2023-07-01 00:00:40 | car-1 |    16 |        0 |      1
 2023-07-01 00:00:41 | car-2 |    34 |        0 |      1
...
 2023-07-01 00:00:22 | car-2 |    57 |        0 |      0
 2023-07-01 00:00:35 | car-1 |    46 |        0 |      0
 2023-07-01 00:00:40 | car-1 |    16 |        0 |      0
```

请注意，数据被划分为存储bucket，存储bucket分布在不同的分片上。数据按每个存储bucket中的ts排序，但您的结果没有排序。
因为查询计划不知道bucketid的不同值，所以它必须对前面的查询执行顺序扫描。为了有效地检索特定汽车（比如car-1）的所有数据，请修改查询以显式调用bucket，如下所示：

```
SELECT * FROM global_order2 WHERE bucketid IN (0,1,2,3,4,5,6,7) ORDER BY ts ASC;
         ts          |  car  | speed | bucketid
---------------------+-------+-------+----------
 2023-07-01 00:00:01 | car-2 |     7 |        1
 2023-07-01 00:00:02 | car-1 |    27 |        6
 2023-07-01 00:00:03 | car-1 |    32 |        1
 2023-07-01 00:00:04 | car-2 |    28 |        6
 2023-07-01 00:00:05 | car-2 |    45 |        2
 2023-07-01 00:00:06 | car-1 |    14 |        3
 2023-07-01 00:00:07 | car-1 |    14 |        1
 2023-07-01 00:00:08 | car-1 |    35 |        5
 2023-07-01 00:00:09 | car-1 |    58 |        3
```

您可以执行示例查询计划来验证前面的查询是否使用主键索引，如下所示： 

```
EXPLAIN ANALYZE SELECT * FROM global_order2 WHERE bucketid IN (0,1,2,3,4,5,6,7) ORDER BY ts ASC;
                                               QUERY PLAN
--------------------------------------------------------------------------------------------------------
 Sort (actual time=2.279..2.289 rows=95 loops=1)
   Output: ts, car, speed, bucketid
   Sort Key: global_order2.ts
   Sort Method: quicksort  Memory: 32kB
   ->  Index Scan using global_order2_pkey on public.global_order2 (actual time=2.139..2.207 rows=95 loops=1)
         Output: ts, car, speed, bucketid
         Index Cond: (global_order2.bucketid = ANY ('{0,1,2,3,4,5,6,7}'::integer[]))
 Planning Time: 0.180 ms
 Execution Time: 2.388 ms
 Peak Memory Usage: 34 kB
```

#### **按每个实体的时间排序**

在时间序列数据模型中，为了强制一个实体的所有数据保持在一起，同时保持基于时间戳的排序，您必须按实体分发数据并按时间排序。

以下部分介绍了如何通过几个示例按实体进行排序 

1. 排序每一实体

考虑一个速度指标跟踪系统，它跟踪来自许多汽车的速度传感器的数据。

创建一个具有示例架构的表，如下所示：

```
CREATE TABLE entity_order1 (
    ts timestamp,/* time at which the event was generated */
    car varchar, /* name of the car */
    speed int,   /* speed of your car */
    PRIMARY KEY(car HASH, ts ASC)
) SPLIT INTO 3 TILES;
```

当您插入数据时，它是按bm_hash_code(car)的值分布的，但在car中，数据是按时间戳排序的。

将数据插入表中，如下所示：

```
INSERT INTO entity_order1 (ts, car, speed)
        (SELECT '2023-07-01 00:00:00'::timestamp + make_interval(secs=>id),
            'car-' || ceil(random()*2), ceil(random()*60)
            FROM generate_series(1,100) AS id);
```

从表中检索数据，如下所示：

```
SELECT * FROM entity_order1 WHERE car = 'car-1' ;
         ts          |  car  | speed
---------------------+-------+-------
 2023-07-01 00:00:01 | car-1 |    22
 2023-07-01 00:00:03 | car-1 |    43
 2023-07-01 00:00:04 | car-1 |    11
 2023-07-01 00:00:07 | car-1 |    39
 2023-07-01 00:00:08 | car-1 |    21
 2023-07-01 00:00:14 | car-1 |     5
 2023-07-01 00:00:15 | car-1 |    31
 2023-07-01 00:00:16 | car-1 |    21
 2023-07-01 00:00:18 | car-1 |    14
 2023-07-01 00:00:19 | car-1 |    46
 2023-07-01 00:00:20 | car-1 |     4
```

car-1的数据自动排序，无需明确要求排序。此外，特定汽车（本例中为car-1）的所有数据都将位于同一分片中，因为您已经定义了要分布在car列哈希的数据（PRIMARY KEY(car hash，ts ASC))。

按实体（car）分发数据，并按每个实体的时间戳排序数据解决了将实体的数据保持在一起的问题，同时在不同的分片上保持不同实体之间的全局分布。但如果同一辆车上有太多操作，这可能会导致热分片问题。

2. 基于bucket的分配
   解决热分片问题的一种方法是使用基于bucket的分发。

Bucketing允许您在特定实体上分发数据，同时保持数据在实体中的有序性。其思想是将实体的数据拆分为bucket，并分发bucket。要理解这一点，请修改上表以添加一个bucketid，如下所示：

```
CREATE TABLE entity_order2 (
    ts timestamp,/* time at which the event was generated */
    car varchar, /* name of the car */
    speed int,   /* speed of your car */
    bucketid smallint DEFAULT random()*8, /* bucket id*/
    PRIMARY KEY((car, bucketid) HASH, ts ASC)
) SPLIT INTO 3 TILES;
```

这将向数据中添加一个bucketid，该bucketid由0到7之间的随机数组成，用于在实体和bucketid上分发数据。

将相同的数据添加到新表中，如下所示：

```
INSERT INTO entity_order2 (ts, car, speed)
        (SELECT '2023-07-01 00:00:00'::timestamp + make_interval(secs=>id),
            'car-' || ceil(random()*2), ceil(random()*60)
            FROM generate_series(1,100) AS id);
```

因为bucketid的默认值设置为random()*8，所以不必显式插入该值。

从表中检索数据，如下所示： 

```
SELECT * FROM entity_order2;
         ts          |  car  | speed | bucketid
---------------------+-------+-------+----------
 2023-07-01 00:00:06 | car-1 |     4 |        7
 2023-07-01 00:00:09 | car-1 |    55 |        7
...
 2023-07-01 00:00:53 | car-1 |     5 |        7
 2023-07-01 00:01:05 | car-1 |     9 |        7
 2023-07-01 00:00:14 | car-2 |    29 |        1
...
 2023-07-01 00:01:00 | car-1 |    24 |        2
 2023-07-01 00:01:37 | car-1 |    13 |        2
 2023-07-01 00:00:11 | car-2 |    30 |        6
 2023-07-01 00:00:30 | car-2 |    30 |        6
...
 2023-07-01 00:01:35 | car-2 |    14 |        6
 2023-07-01 00:00:31 | car-2 |    55 |        0
 2023-07-01 00:00:44 | car-2 |    45 |        0
```

现在，每辆车的数据被划分为多个bucket，每个bucket中的数据按ts排序，buckets分布在不同的分片上。

因为查询计划不知道bucketid的不同值，所以它必须对前面的查询执行顺序扫描。为了有效地检索特定汽车（比如car-1）的所有数据，请修改查询以显式调用bucket，如下所示： 

```
SELECT * FROM entity_order2
    WHERE car='car-1' AND bucketid IN (0,1,2,3,4,5,6,7); 
         ts          |  car  | speed | bucketid
---------------------+-------+-------+----------
 2023-07-01 00:00:21 | car-1 |    45 |        7
 2023-07-01 00:00:22 | car-1 |     9 |        7
 2023-07-01 00:00:37 | car-1 |    32 |        7
 2023-07-01 00:00:41 | car-1 |    51 |        7
 2023-07-01 00:00:57 | car-1 |    50 |        7
 2023-07-01 00:01:09 | car-1 |    59 |        7
 2023-07-01 00:01:23 | car-1 |    54 |        7 
```

这使查询计划器能够使用car的主索引bucketid，因为现在它知道了要查找的car和bucketid的值。

```
EXPLAIN ANALYZE SELECT * FROM entity_order2 WHERE car='car-1' AND bucketid IN (0,1,2,3,4,5,6,7);
                                                              QUERY PLAN
------------------------------------------------------------------------------------------------------------------------------
 Index Scan using entity_order2_pkey on entity_order2  (cost=0.00..16.25 rows=100 width=46) (actual time=1.534..1.562 rows=49 loops=1)
   Index Cond: (((car)::text = 'car-1'::text) AND (bucketid = ANY ('{0,1,2,3,4,5,6,7}'::integer[])))
 Planning Time: 0.129 ms
 Execution Time: 1.624 ms
 Peak Memory Usage: 8 kB
```

您可以看到数据在结果集中并没有真正排序。这是因为数据只在每个bucket中排序。将order by子句添加到原始查询中，如下所示： 

```
SELECT * FROM entity_order2 WHERE car='car-1' AND bucketid IN (0,1,2,3,4,5,6,7) ORDER BY ts ASC;
  ts          |  car  | speed | bucketid
---------------------+-------+-------+----------
 2023-07-01 00:00:01 | car-1 |    57 |        4
 2023-07-01 00:00:03 | car-1 |     7 |        5
 2023-07-01 00:00:04 | car-1 |    58 |        6
 2023-07-01 00:00:07 | car-1 |    48 |        3
 2023-07-01 00:00:08 | car-1 |    43 |        2
 2023-07-01 00:00:12 | car-1 |    60 |        1
 2023-07-01 00:00:13 | car-1 |    20 |        2
```

现在您可以看到数据在ts上的顺序是正确的。

#### **自动数据过期**

考虑这样一种情况：您只需要最后几个值，而旧数据没有任何价值，可以清除。通常，这需要设置一个单独的后台作业。但是，使用BMDB，您可以使用Using TTL运算符为列设置过期值。
注意：
基于TTL的过期仅在BCQL中可用。

1. 行级TTL

考虑一个速度指标跟踪系统，它跟踪来自许多汽车的速度传感器的数据。

创建一个表并插入带有示例架构的数据，如下所示： 

```
CREATE KEYSPACE IF NOT EXISTS bigmath;
USE bigmath;
CREATE TABLE exp_demo (
    ts timestamp,/* time at which the event was generated */
    car text, /* name of the car */
    speed int,   /* speed of your car */
    PRIMARY KEY(car, ts)
) WITH CLUSTERING ORDER BY (ts DESC);
INSERT INTO exp_demo(ts,car,speed) VALUES('2023-07-01 10:00:01','car-1',50) USING TTL 10;
INSERT INTO exp_demo(ts,car,speed) VALUES('2023-07-01 10:00:02','car-2',25) USING TTL 15;
INSERT INTO exp_demo(ts,car,speed) VALUES('2023-07-01 10:00:03','car-1',39) USING TTL 15;
INSERT INTO exp_demo(ts,car,speed) VALUES('2023-07-01 10:00:04','car-1',49) USING TTL 20;
INSERT INTO exp_demo(ts,car,speed) VALUES('2023-07-01 10:00:05','car-2', 3) USING TTL 25;
```

插入数据后，立即开始反复选择所有行。最终，您将看到所有数据消失。 

```
SELECT * from exp_demo;
```


2. 列级TTL
   对于更细粒度的过期，您可以设置每列的TTL，而不是对整行设置TTL。例如，请执行以下操作： 
   1）增加一行

```
INSERT INTO exp_demo(ts,car,speed) VALUES('2023-08-01 10:00:01', 'car-5', 50);
```

 

2）获取行

```
SELECT * FROM exp_demo WHERE car='car-5';
 car   | ts                              | speed
-------+---------------------------------+-------
 car-5 | 2023-08-01 17:00:01.000000+0000 |    50
```


3）按如下方式在该行的speed列上设置过期时间：

```
UPDATE exp_demo USING TTL 5 SET speed=10 WHERE car='car-5' AND ts ='2023-08-01 10:00:01';
```

4）等待五秒钟，然后取下car-5的那一行

```
SELECT * FROM exp_demo WHERE car='car-5';
 car   | ts                              | speed
-------+---------------------------------+-------
 car-5 | 2023-08-01 17:00:01.000000+0000 |   null
```

请注意，行存在，但speed列的值为空。

3. 表级TTL
   您可以在表上设置TTL，而不是在行或列级别显式设置TTL。这也有节省空间的好处，因为TTL值只存储在一个位置，而不是每行或每列。

使用default_time_to_live 属性定义表级TTL。 

#### **分区**

分区是指将逻辑上的一个大表拆分为更小的物理部分。BMDB中分区的关键优势在于，因为每个分区都是一个单独的表，所以将最重要的（例如，最新的）数据保留在一个分区中是有效的，而将不那么重要的数据保留在其他分区中是高效的，这样就可以很容易地删除它们。

以下示例更详细地描述了分区的优点。

注意：分区仅仅在BSQL中可用。

1. 配置
   考虑一个场景，在这个场景中，你有很多来自汽车的数据点，而你只关心上个月的数据。尽管您可以执行一条语句来删除超过30天的数据，但由于数据不会立即从底层存储（基于LSM的CoreDB）中删除，这可能会影响扫描性能。

创建一个具有示例架构的表，如下所示： 


```
CREATE TABLE part_demo (
    ts timestamp,/* time at which the event was generated */
    car varchar, /* name of the car */
    speed int,   /* speed of your car */
    PRIMARY KEY(car HASH, ts ASC)
) PARTITION BY RANGE (ts);
```

为每个月创建分区。此外，为不属于任何其他分区的数据创建一个DEFAULT分区。

```
CREATE TABLE part_7_23 PARTITION OF part_demo
    FOR VALUES FROM ('2023-07-01') TO ('2023-08-01');
 
CREATE TABLE part_8_23 PARTITION OF part_demo
    FOR VALUES FROM ('2023-08-01') TO ('2023-09-01');
 
CREATE TABLE part_9_23 PARTITION OF part_demo
    FOR VALUES FROM ('2023-09-01') TO ('2023-10-01');
 
CREATE TABLE def_part_demo PARTITION OF part_demo DEFAULT;
```

在主表part_demo中插入一些数据： 

```
INSERT INTO part_demo (ts, car, speed)
    (SELECT '2023-07-01 00:00:00'::timestamp +
        make_interval(secs=>id, months=>((random()*2)::int)),
        'car-' || ceil(random()*2), ceil(random()*60)
        FROM generate_series(1,100) AS id);
```

如果从相应的分区中检索行，请注意，它们具有相应日期范围的行。例如：

```
SELECT * FROM part_9_23 LIMIT 4;
         ts          |  car  | speed
---------------------+-------+-------
 2023-09-01 00:00:04 | car-2 |    45
 2023-09-01 00:00:05 | car-2 |    38
 2023-09-01 00:00:08 | car-2 |    49
 2023-09-01 00:00:23 | car-2 |    33
```

2. 获取数据

尽管数据作为分区存储在不同的表中，但要访问所有数据，只需要查询父表。如下所示，查看所选查询的查询计划： 

```
EXPLAIN ANALYZE SELECT * FROM part_demo;
                                  QUERY PLAN
-------------------------------------------------------------------------------
 Append (actual time=1.085..5.351 rows=100 loops=1)
   ->  Seq Scan on public.part_7_23 (actual time=1.079..2.431 rows=25 loops=1)
         Output: part_7_23.ts, part_7_23.car, part_7_23.speed
   ->  Seq Scan on public.part_8_23 (actual time=0.665..1.555 rows=47 loops=1)
         Output: part_8_23.ts, part_8_23.car, part_8_23.speed
   ->  Seq Scan on public.part_9_23 (actual time=0.648..1.342 rows=28 loops=1)
         Output: part_9_23.ts, part_9_23.car, part_9_23.speed
 Planning Time: 0.105 ms
 Execution Time: 5.434 ms
 Peak Memory Usage: 19 kB
```

查询父表时，会自动查询子分区

3. 获取时间范围内的数据
   由于数据是根据时间划分的，因此在查询特定时间范围时，查询执行器仅从数据预期所在的分区中获取数据。例如，请参阅获取特定月份数据的查询计划

```
EXPLAIN ANALYZE SELECT * FROM part_demo WHERE ts > '2023-07-01' AND ts < '2023-08-01';
                                   QUERY PLAN
-----------------------------------------------------------------------------------------------------------
 Append (actual time=2.288..2.310 rows=25 loops=1)
   ->  Seq Scan on public.part_7_23 (actual time=2.285..2.301 rows=25 loops=1)
         Output: part_7_23.ts, part_7_23.car, part_7_23.speed
         Remote Filter: ((part_7_23.ts > '2023-07-01 00:00:00'::timestamp without time zone)
                AND (part_7_23.ts < '2023-08-01 00:00:00'::timestamp without time zone))
 Planning Time: 0.309 ms
 Execution Time: 2.411 ms
 Peak Memory Usage: 14 kB
```

您可以看到查询计划只选择了一个分区来从中获取数据 

4. 删除旧数据
   数据分区的主要优点是可以轻松地丢弃较旧的数据。要删除旧数据，您所需要做的就是删除特定的分区表。例如，当不需要第7个月的数据时，请执行以下操作：

```
DROP TABLE part_7_23;
DROP TABLE
Time: 103.214 ms
```


### **键值**

在键值数据模型中，每个键都与一个且仅与一个值相关联。键值存储公开了三个基本API：

* GET获取键的值（例如，GET('name')）
* SET存储键的值（例如，SET('name'，'bigmath')）
* DEL删除键及其值（例如，DEL('name')） 

有了这三个简单的功能，键值存储凭借其速度和简单性在现代基础设施中占据了一席之地。
BMDB在用键值存储时提供了几个优势：
BMDB内部将数据存储为键值对的集合，因此自动成为键值存储。
BMDB在设计上是分布式的，自然也可以作为分布式键值存储。
由于RAFT复制，BMDB固有地提供了数据的一致性，而其他键值存储通常无法保证这一点。 

#### **存储用户数据**

例如，为了存储用户的详细信息，可以采用一个模式，其中每个属性都是一个单独的键，例如以下内容：

```
user1.name = "John Wick"
user1.country = "USA"
user2.name = "Harry Potter"
user2.country = "UK"
```

为此，您可以创建一个表，如下所示： 

```
CREATE TABLE kvstore (
    key VARCHAR,
    value VARCHAR,
    PRIMARY KEY(key)
);
```

要添加一些数据，请输入以下内容：

```
INSERT INTO kvstore VALUES ('user1.name', 'John Wick'), ('user1.country', 'USA'),
                           ('user2.name', 'Harry Potter'), ('user2.country', 'UK');
```

1. GET
   要获取user1的名称，您可以执行以下操作： 

```
SELECT value FROM kvstore WHERE key = 'user1.name';
   value
-----------
 John Wick
```

2. SET
   要存储键的值，可以执行插入操作。因为key 可能已经存在，所以应该提供一个ON CONFLICT UPDATE子句。 

```
INSERT INTO kvstore(key, value) VALUES('user1.name', 'Jack Ryan') 
        ON CONFLICT (key) DO
        UPDATE SET value = EXCLUDED.value;
```

3. DEL
   要删除键及其值，可以执行如下简单的delete命令 

```
DELETE FROM kvstore WHERE key = 'user1.name';
```


#### **适用举例**

1. 缓存服务器
   键值数据模型最适合设计缓存服务器，其中缓存的数据由键表示。缓存的对象可以用JSON字符串表示（具有多个属性），并由应用程序进行解析。

2. 电话簿
   电话簿键值模型，其中键是电话号码，值是电话号码所属人员的姓名和地址。

3. 会话存储
   面向会话的应用程序，如web应用程序，在用户登录时启动会话，并一直处于活动状态，直到用户注销或会话超时。在此期间，应用程序将所有与会话相关的数据，如配置文件信息、主题、邮政编码、地理位置等进行键值存储。

4. 购物车
   用户的购物车可以表示为JSON字符串，并存储在一个键下，例如user1.cart。由于BMDB提供了强大的一致性和弹性，即使发生灾难，购物车信息也不会丢失。
