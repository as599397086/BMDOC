# **数据迁移**

## **批量导出**

本节描述了将 PostgreSQL 数据导出到 BMDB 所需的以下步骤：

* 转换 PostgreSQL 模式
* 迁移 PostgreSQL 应用程序
* 导出 PostgreSQL 数据

### **转换 PostgreSQL 模式**

要将 PostgreSQL 模式转换为 BMDB 模式，需要进行以下更改。

提示
bm-dump 工具可以简化架构迁移的一些步骤，请参阅使用 bm-dump。

**1.内联指定 PRIMARY KEY**（在表定义中指定主键）
BMDB 支持首先声明表，然后运行 ALTER TABLE 命令来添加主键的 PostgreSQL 语法。 请注意，ALTER TABLE 操作需要重新写入磁盘，并且可能会占用大量资源，因此建议将主键内联设置为 CREATE TABLE 操作的一部分。

**2.使用 HASH 排序顺序**
在 BMDB 中，表的主键（或索引）的排序顺序决定了该主键（或索引）表在集群节点上的数据分布策略。 因此，排序顺序的选择对于确定数据分布策略至关重要。

使用 ASC 或 DESC 排序顺序的索引可以有效地处理点查找和范围查找。 然而，它们将从单个tile开始，因此对该表的所有读取和写入最初都将由单个tile处理。 Tile需要对表进行动态拆分以利用多个节点。 当不需要范围查询时，为大型数据集创建 ASC 或 DESC 排序顺序可能会导致热分片问题。

为了克服上述问题，BMDB 除了标准的 ASC 和 DESC 索引排序顺序之外，还支持 HASH 排序。 对于 HASH 排序，首先通过对相应列的值应用哈希函数来计算哈希值，然后对哈希值进行排序。 由于排序顺序实际上是随机的，因此这会导致数据在集群中的各个节点上随机分布。 数据的随机分布具有以下属性：

* 它可以通过在所有节点上均匀分布数据来消除集群中的热点。
* 该表可以预先分割，以便从一开始就利用集群的所有节点。
* 索引无法有效支持范围查询。

**3.优化包含多个对象的数据库**

提示
拥有超过 500 个对象（主要是表、索引和唯一约束）的数据库可以从共址中受益。 共址还可以提高较小表的连接性能。

在许多场景中，可能存在大量数据库对象（特别是表和索引），而它们保存着相对较小的数据集。 在这种情况下，为每个表和索引创建单独的tile可能会大大降低性能。 将这些表和索引共址到单个tile中可以极大地提高性能。

在数据库级别启用共址属性会导致默认情况下在此数据库中创建的所有表都共址。 该数据库中包含大型数据集的表或预计大小会随着时间的推移而增长的表可以选择退出共址组，这将导致它们被拆分为多个Tile。

有关更多信息，请参阅共址表。

**4.预分割大表**
对于散列分片的较大表和索引，请指定所需的初始Tile分割数作为表的 DDL 语句的一部分。 这对于从一开始就将表的数据分布在多个节点上非常有利。 有关在表创建时指定 Tile 数量的示例，请参阅哈希分片表。

对于范围分片的较大表和索引，并且提前知道主键列的值范围，请在创建时对其进行预分割。 这对于范围分片表/索引特别有利。 有关预分割索引的语法，请参阅 range-sharded-tables。

**5.删除列上的排序规则**
删除 COLLATE 选项以便将架构移至 BMDB。 请参阅排序规则以了解更多信息。

例如，请考虑下表定义。

```
CREATE TABLE test1 (
    a text COLLATE "de_DE" PRIMARY KEY,
    b text COLLATE "es_ES"
);
```

尝试创建此表将导致以下错误。

```
ERROR:  0A000: COLLATE not supported yet
LINE 2:     a text COLLATE "de_DE" PRIMARY KEY,
                   ^
HINT:  See https://gitlab.bigmath.com/bigmath/bigmath-db/issues/1127. Click '+' on the description to raise its priority
LOCATION:  raise_feature_not_supported_signal, gram.y:17113
Time: 31.543 ms
```

应按如下方式删除 COLLATE 选项：

```
CREATE TABLE test1 (
    a text PRIMARY KEY,
    b text
);
```

**6.优化序列（SERIAL）**
模式中的所有序列当前使用默认 CACHE 值 1。在分布式数据库中，这将导致每个 INSERT 执行额外的 RPC 调用来生成新的行 ID，从而显着降低写入性能。

请考虑下表作为示例。

```
CREATE TABLE contacts (
  contact_id SERIAL,
  first_name VARCHAR NOT NULL,
  last_name VARCHAR NOT NULL,
  email VARCHAR NOT NULL,
  phone VARCHAR,
  PRIMARY KEY (contact_id)
);
```

建议使用以下技术之一（按优先顺序）以提高使用序列时的性能。

选项 1. SERIAL 的较大 CACHE 值
为了使用 SERIAL 数据类型并且不会对 INSERT 操作造成性能损失，建议将缓存大小设置为 1000。 在上面的示例表中，这可以通过按以下方式对序列运行 ALTER 命令来实现。

```
ALTER SEQUENCE contacts_contact_id_seq CACHE 1000;
```

您可以按如下方式找到序列的名称：

```
bigmath=# SELECT pg_get_serial_sequence('contacts', 'contact_id');
     pg_get_serial_sequence
--------------------------------
 public.contacts_contact_id_seq
(1 row)
```

选项 2. 使用 UUID 代替 SERIAL
建议的选项是使用 UUID 而不是 SERIAL 数据类型。 UUID 是全局唯一标识符，可以在任何节点上生成，无需任何全局节点间协调。

有些系统将此数据类型称为全局唯一标识符或 GUID。

UUID 是一个 128 位的数量，由所选择的算法生成，该算法使得已知宇宙中的任何其他人使用相同算法生成相同标识符的可能性很小。 因此，对于分布式系统来说，这些标识符比序列生成器提供了更好的唯一性保证，序列生成器仅在单个数据库中唯一。

上一示例中显示的表应更改如下：

```
CREATE EXTENSION IF NOT EXISTS pgcrypto;
CREATE TABLE contacts (
  contact_id uuid DEFAULT gen_random_uuid(),
  first_name VARCHAR NOT NULL,
  last_name VARCHAR NOT NULL,
  email VARCHAR NOT NULL,
  phone VARCHAR,
  PRIMARY KEY (contact_id)
);
```

**7.使用 bm-dump**
PostgreSQL 实用程序 pg_dump 可用于转储数据库的架构，如本文档前面部分所述。

bm-dump 工具（pg_dump 工具的 BMDB 特定版本）可以连接到现有 PostgreSQL 数据库并导出 BMDB 友好版本的架构，因此包括一些架构修改。 根据用例，可能需要其他手动更改。

请注意，bm-dump 已在 PostgreSQL 版本高达 11.2 上进行了测试，可能不适用于较新版本的 PostgreSQL。

### **迁移 PostgreSQL 应用程序**

本节概述了将现有 PostgreSQL 应用程序移植到 BMDB 的建议更改。

**1.发生冲突时重试事务**
仅透明地重试由于内部冲突而中止的事务子集。 BMDB 使用错误代码 40001 (serialization_failure) 来表示可重试的事务冲突错误。 我们建议在遇到这些错误时从应用程序重试事务。

注：这是 BMDB v2.2 的状态，通过透明地处理大多数事务的重试来减少事务冲突正在进行中。

**2.在集群中均匀分配负载**
集群中的所有节点（DBServer）都是相同的并且能够处理查询。 但是，PostgreSQL 的客户端驱动程序设计为仅与单个端点（节点）通信。 为了均匀地利用集群的所有节点，来自应用程序的查询需要均匀分布在集群的所有节点上。 有两种方法可以实现此目的：

* 使用负载均衡器来前置集群的所有节点。 负载均衡器应设置为对集群中节点上的所有请求进行循环。
* 修改应用程序以跨集群中的节点分发查询。 在这种情况下，通常使用 DNS 条目来维护集群中的节点列表。 应用程序定期刷新此列表，并以循环方式将查询分布在集群的各个节点上。

**3.处理大量连接**
在许多应用程序中，处理大量客户端连接至关重要。 有两种策略可以解决这个问题：

* 跨节点均匀分布查询：BMDB 集群的每个节点（bm-dbserver 进程）对其可以处理的连接数量都有限制，默认情况下该数量为 300 个连接。 虽然这个数字可以根据用例增加一点，但建议将查询分布在集群中的不同节点上。 例如，一个 10 节点集群，每个节点包含 16 个 vCPU，可以处理 3000 个连接。
* 使用连接池：在应用程序中使用连接池，例如 Hikari 池。 使用连接池可将大量逻辑客户端连接复用到 BMDB 集群节点上的少量物理连接上，从而显着减少连接数量。
* 增加集群中的节点数量：请注意，BMDB 集群的连接数量与集群中的节点数量成线性比例。 通过部署更多节点且每个节点的 vCPU 更小，可以获得更多连接。 例如，每个节点包含 32 个 vCPU 的 10 节点集群可以处理 3000 个连接。 如果需要更多连接，部署每个节点 16 个 vCPU 的 20 节点集群（相当于 10 个节点、32 个 vCPU 集群）可以处理 6000 个连接。

**4.使用 PREPARED 语句**
Prepared statement对于在 BMDB 中实现良好的性能至关重要，因为它们避免了对每个查询进行重新解析（通常是重新生成执行计划）。 大多数 SQL 驱动程序会auto-prepare statements，在这些情况下，可能不需要显式Prepared statement。

如果驱动程序不auto-prepare，请尽可能使用显式Prepared statement。 对于许多驱动程序来说，这可以通过编程来完成。 在驱动程序不支持Prepared statement的情况下（例如，Python psycopg2 驱动程序），可以使用 PREPARE AS 功能在每个服务器上优化查询。

例如，如果您有两个表 t1 和 t2，它们都有两列 k（主键）和 v：

```
CREATE TABLE t1 (k VARCHAR PRIMARY KEY, v VARCHAR);
 
CREATE TABLE t2 (k VARCHAR PRIMARY KEY, v VARCHAR);
```

现在，考虑以下代码片段，该代码片段反复进行未准备好的 SELECT 查询。

```
for idx in range(num_rows):
  cur.execute("SELECT * from t1, t2 " +
              "  WHERE t1.k = t2.k AND t1.v = %s LIMIT 1"
              , ("k1"))
```

由于Python psycopg2 驱动程序不支持PREPARE 的绑定语句（使用cursor.prepare() API），因此使用显式PREPARE 语句。 可以通过将上述查询更改为以下等效查询来优化上述代码片段。

```
cur.execute("PREPARE myplan as " +
            "  SELECT * from t1, t2 " +
            "  WHERE t1.k = t2.k AND t1.v = $1 LIMIT 1")
  for idx in range(num_rows):
    cur.execute("""EXECUTE myplan(%s)""" % "'foo'")
```

### **导出 PostgreSQL 数据**

从 PostgreSQL 导出数据以将其导入 BMDB 的推荐方法是使用 COPY 命令通过 CSV 文件。 但是，要导出由较小数据集组成的整个数据库，您可以使用 BMDB bm-dump 实用程序。

使用 BMDB Voyager 进行迁移
要自动从 PostgreSQL 迁移到 BMDB，请使用 BMDB Voyager。 要了解更多信息，请参阅导出架构和导出数据步骤。

1.使用 COPY 命令将数据导出到 CSV 文件
要导出数据，请使用psql工具连接到源PostgreSQL数据库，然后执行COPY TO命令，如下所示：

```
COPY <table_name>
    TO '<table_name>.csv'
    WITH (FORMAT CSV, HEADER false, DELIMITER ',');
```

注：COPY TO 命令导出单个表，因此您应该对要导出的每个表执行该命令。

还可以根据条件导出行的子集：

```
COPY (
    SELECT * FROM <table_name>
    WHERE <condition>
)
TO '<table_name>.csv'
WITH (FORMAT CSV, HEADER false, DELIMITER ',');
```

有关 COPY TO 命令提供的所有可用选项，请参阅 PostgreSQL 文档。

**并行化大表导出**
对于大型表，通过按块导出数据来并行化该过程可能是有益的，如下所示：

```
COPY (
    SELECT * FROM <table_name>
    ORDER BY <primary_key_col>
    LIMIT num_rows_per_export OFFSET 0
)
TO '<table_name>_1.csv'
WITH (FORMAT CSV, HEADER false, DELIMITER ',');
COPY (
    SELECT * FROM <table_name>
    ORDER BY <primary_key_col>
    LIMIT num_rows_per_export OFFSET num_rows_per_export
)
TO '<table_name>_2.csv'
WITH (FORMAT CSV, HEADER false, DELIMITER ',');
COPY (
    SELECT * FROM <table_name>
    ORDER BY <primary_key_col>
    LIMIT num_rows_per_export OFFSET num_rows_per_export * 2
)
TO '<table_name>_3.csv'
WITH (FORMAT CSV, HEADER false, DELIMITER ',');
```

您可以并行运行上述命令以加快该过程。 这种方法还将生成多个 CSV 文件，允许在 BMDB 端并行导入。

2.使用 bm-dump 将数据导出到 SQL 脚本
导出数据的另一种方法是使用 BMDB bm-dump 备份实用程序，它源自 PostgreSQL pg_dump。

```
$ bm-dump -d <database_name> > <database_name>.sql
```

bm-dump 是较小数据集的理想选择，因为它允许您通过运行单个命令来导出整个数据库。 但是，对于大型数据库，建议使用 COPY 命令，因为它可以显着提高性能。


## **批量导入**

本节介绍了导出 PostgreSQL 数据后手动将 PostgreSQL 数据和应用程序迁移到 BMDB 的以下步骤。

* 准备集群
* 导入 PostgreSQL 数据
* 验证迁移

### **准备集群**

本节概述了将数据加载到集群之前的一些重要注意事项。

1.将 DDL 架构与数据分离
建议在加载导出的数据之前先运行 DDL 生成架构。 这对于确保在开始使用表之前正确创建表至关重要。

2.按主键排序数据
如果可能的话，导入数据时应按主键排序。 导入按主键排序的数据集通常要快得多，因为正在加载的数据将作为较大一批行全部写入节点，而不是跨多个节点写入几行。

3.多个平行导入
如果将导入的源数据拆分为多个文件，以便可以跨集群节点并行导入这些文件，则效率会更高。 这可以通过并行运行多个 COPY 命令来完成。 例如，大型 CSV 数据文件应拆分为多个较小的 CSV 文件。

4.程序化批量插入
以下是以编程方式执行批量数据加载时的一些建议。
（1）使用多行插入来进行批处理。 这需要根据所使用的驱动程序设置某些属性。 例如，对于使用 Java 的 JDBC 驱动程序，设置以下属性以使用多行插入： reWriteBatchedInserts=true
（2）使用多行批量插入时，请使用 128 的批量大小。
（3）使用 PREPARE - BIND - EXECUTE 范例而不是内联文字，以避免语句重新解析开销。
（4）为了通过平衡负载来确保集群中所有节点的最佳利用率，请将 SQL 语句均匀分布在集群中的所有节点上。
（5）在某些场景下可能需要增加负载的并行度。 例如，在加载器使用单个线程加载数据的情况下，可能无法最佳地利用大集群。 在这些情况下，可能需要增加线程数量或并行运行多个加载程序。
（6）请注意，从 BMDB v2.2 开始，INSERT .. ON CONFLICT 语句尚未完全优化，因此建议尽可能使用基本 INSERT 语句。

5.数据加载期间的索引
从 BMDB v2.2 开始，建议在加载数据之前创建索引。

注：随着在线索引重建的引入，此建议可能会在不久的将来发生变化，在线索引重建可以在加载所有数据后创建索引。

6.暂时禁用约束和触发器
当加载从另一个 RDBMS 导出的数据时，可能不一定需要检查源数据集的关系完整性，因为这在插入源数据库时已经执行过。 在这种情况下，请禁用外键约束等检查以及触发器（如果可能）。 这将减少数据库在插入数据时需要执行的步骤数，从而加快数据加载速度。

### **导入 PostgreSQL 数据**

使用 BMDB Voyager 进行迁移
要自动从 PostgreSQL 迁移到 BMDB，请使用 BMDB Voyager。 要了解更多信息，请参阅导入架构和导入数据步骤。

1.从 CSV 文件导入数据
要导入之前导出到 CSV 文件中的数据，请使用 COPY FROM 命令，如下所示：

```
COPY <table_name>
    FROM '<table_name>.csv'
    WITH (FORMAT CSV DELIMITER ',', HEADER, DISABLE_FK_CHECK);
```

在上面的命令中，DISABLE_FK_CHECK 参数在导入过程期间跳过外键检查。 建议在数据的初始导入时提供 DISABLE_FK_CHECK 参数，特别是对于大型表，因为它可以减少导入数据所需的总时间。

为了进一步加快该过程，您可以在单个 COPY 命令中导入多个文件。 以下是一个示例：

```
bigmath=# \! ls t*.txt
t1.txt t2.txt t3.txt
bigmath=# \! cat t*.txt
1,2,3
4,5,6
7,8,9
bigmath=# \d t
 
                 Table "public.t"
 Column |  Type   | Collation | Nullable | Default
--------+---------+-----------+----------+---------
 c1     | integer |           |          |
 c2     | integer |           |          |
 c3     | integer |           |          |
bigmath=# SELECT * FROM t;
 
 c1 | c2 | c3
----+----+----
(0 rows)
bigmath=# COPY t FROM PROGRAM 'cat /home/bigmath/t*.txt' WITH (FORMAT CSV, DELIMITER ',', DISABLE_FK_CHECK);
COPY 3
bigmath=# SELECT * FROM t;
 
 c1 | c2 | c3
----+----+----
  7 |  8 |  9
  4 |  5 |  6
  1 |  2 |  3
(3 rows)
```

有关 COPY FROM 命令的详细信息，请参阅 COPY 语句参考。

**错误处理**
如果 COPY FROM 命令在此过程中失败，您应该尝试重新运行它。 但是，您不必重新运行整个文件。 COPY FROM 从文件顶部开始将数据单独导入到行中。 因此，如果您知道某些行在失败之前已成功导入，则可以通过添加 SKIP 参数安全地忽略这些行。

例如，要跳过文件中的前 5000 行，请运行以下命令：

```
COPY <table_name>
    FROM '<table_name>.csv'
    WITH (FORMAT CSV DELIMITER ',', HEADER, DISABLE_FK_CHECK, SKIP 5000);
```

2.从 SQL 脚本导入数据
要从 pg_dump 或 bm-dump 导出导入整个数据库，请使用 sqlsh，如下所示：
sqlsh -f <database_name>.sql

注：数据导入步骤完成后，请记住重新创建可能已禁用的所有约束和触发器，以加快数据加载速度。 这确保数据库将对未来的数据执行关系完整性检查。

### **验证迁移**

以下是一些可验证的步骤，以确保迁移成功。

1.验证数据库对象

* 验证 BMDB 中是否已创建所有表和索引。
* 确保触发器和约束已迁移并按预期工作。

2.验证表的行数
运行 COUNT(*) 命令以验证源数据库和 BMDB 之间的总行数是否匹配。

**使用 PLPGSQL 函数执行以下操作：**

1创建以下函数来打印单个表中的行数：

```
create function
cnt_rows(schema text, tablename text) returns integer
as
$body$
declare
  result integer;
  query varchar;
begin
  query := 'SELECT count(1) FROM ' || schema || '.' || tablename;
  execute query into result;
  return result;
end;
$body$
language plpgsql;
```

2.运行以下命令打印数据库中所有表的大小。

```
SELECT cnt_rows(table_schema, table_name)
    FROM information_schema.tables
    WHERE table_schema NOT IN ('pg_catalog', 'information_schema')
    AND table_type='BASE TABLE'
    ORDER BY 3 DESC;
```

以下示例显示了在 Northwind 数据库上运行上一个示例的输出。

```
example=# SELECT cnt_rows(table_schema, table_name)
    FROM information_schema.tables
    WHERE table_schema NOT IN ('pg_catalog', 'information_schema')
    AND table_type='BASE TABLE'
    ORDER BY 3 DESC;
 table_schema |       table_name       | cnt_rows
--------------+------------------------+----------
 public       | order_details          |     2155
 public       | orders                 |      830
 public       | customers              |       91
 public       | products               |       77
 public       | territories            |       53
 public       | us_states              |       51
 public       | employee_territories   |       49
 public       | suppliers              |       29
 public       | employees              |        9
 public       | categories             |        8
 public       | shippers               |        6
 public       | region                 |        4
 public       | customer_customer_demo |        0
 public       | customer_demographics  |        0
(14 rows)
```

**Timeouts** 
如果表很大，则 COUNT(*) 查询可能会超时。 对于此类用例，建议使用以下两个选项：
选项 1：创建一个函数并使用使用隐式游标的函数执行查询。

```
CREATE OR REPLACE FUNCTION row_count(tbl regclass)
    RETURNS setof int AS
$func$
DECLARE
    _id int;
BEGIN
    FOR _id IN
        EXECUTE 'SELECT 1 FROM ' || tbl
    LOOP
        RETURN NEXT _id;
    END LOOP;
END
$func$ LANGUAGE plpgsql;
```

在这种情况下，查询将是：

```
select count(*) from row_count('tablename');
```

此查询可能需要一些时间才能完成。 您可以使用 DBServer 标志 --client_read_write_timeout_ms=600000 将客户端超时增加到更高的值，例如 10 分钟。

以下示例是在 sqlsh 中运行 COUNT(*) 的另一个解决方法：

```
create table test (id int primary key, fname text);
insert into test select i, 'jon' || i from generate_series(1, 1000000) as i;
create table dual (test int);
insert into dual values (1);
explain select count(*) from test cross join dual;
 
                                QUERY PLAN
---------------------------------------------------------------------------
 Aggregate  (cost=15202.50..15202.51 rows=1 width=8)
   ->  Nested Loop  (cost=0.00..12702.50 rows=1000000 width=0)
         ->  Seq Scan on test  (cost=0.00..100.00 rows=1000 width=0)
         ->  Materialize  (cost=0.00..105.00 rows=1000 width=0)
               ->  Seq Scan on dual  (cost=0.00..100.00 rows=1000 width=0)
```

选项 2：使用 bm_hash_code() 运行针对表的不同部分的不同查询，并控制应用程序级别的并行性。
有关使用 bm_hash_code() 在表上运行 COUNT(*) 的更多信息，请参阅分布式并行查询。